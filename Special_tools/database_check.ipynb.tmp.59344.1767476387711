{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0490f03",
   "metadata": {},
   "source": [
    "# Database Check\n",
    "Validate raw + derived tables and provenance for the FINRA + Polygon pipeline.\n",
    "\n",
    "| Cell | Description |\n",
    "|------|-------------|\n",
    "| 1 | Setup - imports and database connection |\n",
    "| 2 | List all tables in the database |\n",
    "| 3 | Describe schema and row count for each table |\n",
    "| 4 | Define sample parameters for queries |\n",
    "| **5** | **Data Completeness - newest/oldest 5 days + NULL flagging** |\n",
    "| **6** | **Multi-Table Health Summary** |\n",
    "| 7 | Sample FINRA OTC weekly data |\n",
    "| 8 | Sample FINRA short daily data |\n",
    "| 9 | Sample Polygon daily aggregates |\n",
    "| 10 | Sample Polygon equity trades (tick data) |\n",
    "| 11 | Sample lit direction daily (buy/sell flow) |\n",
    "| 12 | Sample daily metrics (combined analysis table) |\n",
    "| 13 | Sample index constituent short aggregates |\n",
    "| 14 | Coverage check - row counts by symbol |\n",
    "| 15 | Provenance check - OTC week mapping |\n",
    "| 16-19 | Sanity checks (lit volumes, short ratios, duplicates) |\n",
    "| 20-25 | Lit diagnostics section |\n",
    "| 26 | Cleanup - close database connection |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup - imports and database connection\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add darkpool root to path for darkpool_analysis imports\n",
    "darkpool_root = Path(__file__).parent.parent if '__file__' in dir() else Path.cwd().parent\n",
    "sys.path.insert(0, str(darkpool_root))\n",
    "\n",
    "from darkpool_analysis.config import load_config\n",
    "from darkpool_analysis.db import get_connection\n",
    "import pandas as pd\n",
    "\n",
    "config = load_config()\n",
    "conn = get_connection(config.db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: List all tables in the database\n",
    "tables = conn.execute(\"SHOW TABLES\").df()[\"name\"].tolist()\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for table in tables:\n",
    "    print(table)\n",
    "    display(conn.execute(f\"DESCRIBE {table}\").df())\n",
    "    display(conn.execute(f\"SELECT COUNT(*) AS n FROM {table}\").df())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_symbol = \"META\"\n",
    "start_date = min(config.target_dates)\n",
    "end_date = max(config.target_dates)\n",
    "sample_symbol, start_date, end_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zqs1yhgxppa",
   "metadata": {},
   "source": [
    "## Data Completeness Check\n",
    "Verify database has recent data and flag any missing/NULL fields for a sample ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q46lp1v2dso",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Data Completeness Check - newest/oldest 5 days with NULL field flagging\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "check_symbol = \"AAPL\"  # Change to test different tickers\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"DATA COMPLETENESS CHECK FOR: {check_symbol}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Get newest 5 days\n",
    "print(\"\\nüìÖ NEWEST 5 DAYS (daily_metrics):\")\n",
    "newest = conn.execute(\"\"\"\n",
    "    SELECT * FROM daily_metrics\n",
    "    WHERE symbol = ?\n",
    "    ORDER BY date DESC\n",
    "    LIMIT 5\n",
    "\"\"\", [check_symbol]).df()\n",
    "display(newest)\n",
    "\n",
    "# Get oldest 5 days\n",
    "print(\"\\nüìÖ OLDEST 5 DAYS (daily_metrics):\")\n",
    "oldest = conn.execute(\"\"\"\n",
    "    SELECT * FROM daily_metrics\n",
    "    WHERE symbol = ?\n",
    "    ORDER BY date ASC\n",
    "    LIMIT 5\n",
    "\"\"\", [check_symbol]).df()\n",
    "display(oldest)\n",
    "\n",
    "# Combine for NULL analysis\n",
    "combined = pd.concat([newest, oldest], ignore_index=True)\n",
    "\n",
    "# Count NULLs per column\n",
    "print(\"\\nüîç NULL FIELD ANALYSIS (across newest + oldest 10 rows):\")\n",
    "null_counts = combined.isnull().sum()\n",
    "total_rows = len(combined)\n",
    "\n",
    "# Create summary dataframe\n",
    "null_summary = pd.DataFrame({\n",
    "    'column': null_counts.index,\n",
    "    'null_count': null_counts.values,\n",
    "    'total_rows': total_rows,\n",
    "    'null_pct': (null_counts.values / total_rows * 100).round(1),\n",
    "    'status': ['‚ö†Ô∏è MISSING' if n > 0 else '‚úÖ OK' for n in null_counts.values]\n",
    "})\n",
    "\n",
    "# Show only columns with issues first, then OK columns\n",
    "null_summary_sorted = null_summary.sort_values(['null_count', 'column'], ascending=[False, True])\n",
    "display(null_summary_sorted)\n",
    "\n",
    "# Summary flag\n",
    "missing_cols = null_summary[null_summary['null_count'] > 0]['column'].tolist()\n",
    "if missing_cols:\n",
    "    print(f\"\\n‚ö†Ô∏è  ALERT: {len(missing_cols)} columns have NULL values:\")\n",
    "    for col in missing_cols:\n",
    "        pct = null_summary[null_summary['column'] == col]['null_pct'].values[0]\n",
    "        print(f\"   - {col}: {pct}% null\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ALL FIELDS POPULATED - No NULL values detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7l17xupg8s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Multi-Table Data Health Summary - check all key tables for sample ticker\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MULTI-TABLE HEALTH CHECK FOR: {check_symbol}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define tables and their date columns\n",
    "table_checks = [\n",
    "    (\"daily_metrics\", \"date\", \"symbol\"),\n",
    "    (\"lit_direction_daily\", \"date\", \"symbol\"),\n",
    "    (\"finra_short_daily_raw\", \"trade_date\", \"symbol\"),\n",
    "    (\"polygon_daily_agg_raw\", \"trade_date\", \"symbol\"),\n",
    "]\n",
    "\n",
    "health_rows = []\n",
    "\n",
    "for table, date_col, sym_col in table_checks:\n",
    "    try:\n",
    "        result = conn.execute(f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as row_count,\n",
    "                MIN({date_col}) as oldest_date,\n",
    "                MAX({date_col}) as newest_date\n",
    "            FROM {table}\n",
    "            WHERE {sym_col} = ?\n",
    "        \"\"\", [check_symbol]).df()\n",
    "        \n",
    "        row_count = result['row_count'].iloc[0]\n",
    "        oldest = result['oldest_date'].iloc[0]\n",
    "        newest = result['newest_date'].iloc[0]\n",
    "        \n",
    "        # Check if newest date is within last 7 days\n",
    "        if newest and pd.Timestamp(newest) >= pd.Timestamp.now() - pd.Timedelta(days=7):\n",
    "            freshness = \"‚úÖ FRESH\"\n",
    "        elif newest:\n",
    "            freshness = \"‚ö†Ô∏è STALE\"\n",
    "        else:\n",
    "            freshness = \"‚ùå NO DATA\"\n",
    "            \n",
    "        health_rows.append({\n",
    "            'table': table,\n",
    "            'rows': row_count,\n",
    "            'oldest': oldest,\n",
    "            'newest': newest,\n",
    "            'freshness': freshness\n",
    "        })\n",
    "    except Exception as e:\n",
    "        health_rows.append({\n",
    "            'table': table,\n",
    "            'rows': 0,\n",
    "            'oldest': None,\n",
    "            'newest': None,\n",
    "            'freshness': f\"‚ùå ERROR: {str(e)[:30]}\"\n",
    "        })\n",
    "\n",
    "health_df = pd.DataFrame(health_rows)\n",
    "display(health_df)\n",
    "\n",
    "# Overall verdict\n",
    "stale_tables = health_df[health_df['freshness'].str.contains('STALE|ERROR|NO DATA', na=False)]['table'].tolist()\n",
    "if stale_tables:\n",
    "    print(f\"\\n‚ö†Ô∏è  ATTENTION: {len(stale_tables)} table(s) may need refresh:\")\n",
    "    for t in stale_tables:\n",
    "        print(f\"   - {t}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ALL TABLES HAVE FRESH DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT * FROM finra_otc_weekly_raw\n",
    "WHERE symbol = ?\n",
    "ORDER BY week_start_date DESC\n",
    "LIMIT 5\n",
    "\"\"\", [sample_symbol]).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT * FROM polygon_daily_agg_raw\n",
    "WHERE symbol = ? AND trade_date BETWEEN ? AND ?\n",
    "ORDER BY trade_date DESC\n",
    "LIMIT 5\n",
    "\"\"\", [sample_symbol, start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT * FROM polygon_equity_trades_raw\n",
    "WHERE symbol = ? AND timestamp::DATE BETWEEN ? AND ?\n",
    "ORDER BY timestamp DESC\n",
    "LIMIT 5\n",
    "\"\"\", [sample_symbol, start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived Tables Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT * FROM lit_direction_daily\n",
    "WHERE symbol = ? AND date BETWEEN ? AND ?\n",
    "ORDER BY date DESC\n",
    "LIMIT 5\n",
    "\"\"\", [sample_symbol, start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT * FROM daily_metrics\n",
    "WHERE symbol = ? AND date BETWEEN ? AND ?\n",
    "ORDER BY date DESC\n",
    "LIMIT 10\n",
    "\"\"\", [sample_symbol, start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT index_symbol, trade_date, coverage_count, expected_constituent_count, coverage_pct\n",
    "FROM index_constituent_short_agg_daily\n",
    "ORDER BY trade_date DESC\n",
    "LIMIT 5\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage and Provenance Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT symbol, COUNT(*) AS rows\n",
    "FROM daily_metrics\n",
    "WHERE date BETWEEN ? AND ?\n",
    "GROUP BY symbol\n",
    "ORDER BY symbol\n",
    "\"\"\", [start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT date, symbol, otc_off_exchange_volume, otc_week_used, data_quality\n",
    "FROM daily_metrics\n",
    "WHERE symbol = ? AND date BETWEEN ? AND ?\n",
    "ORDER BY date DESC\n",
    "\"\"\", [sample_symbol, start_date, end_date]).df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT symbol, date, lit_buy_volume, lit_sell_volume, log_buy_sell\n",
    "FROM lit_direction_daily\n",
    "WHERE (lit_buy_volume <= 0 OR lit_sell_volume <= 0)\n",
    "  AND log_buy_sell IS NOT NULL\n",
    "LIMIT 10\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT symbol, date, short_ratio, short_ratio_denominator_type\n",
    "FROM daily_metrics\n",
    "WHERE short_ratio_denominator_type IS NOT NULL\n",
    "  AND (short_ratio < 0 OR short_ratio > 1)\n",
    "LIMIT 10\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT symbol, date, COUNT(*) AS n\n",
    "FROM daily_metrics\n",
    "GROUP BY symbol, date\n",
    "HAVING n > 1\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.execute(\"\"\"\n",
    "SELECT symbol, date, COUNT(*) AS n\n",
    "FROM lit_direction_daily\n",
    "GROUP BY symbol, date\n",
    "HAVING n > 1\n",
    "\"\"\").df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eqfm78qwpqq",
   "metadata": {},
   "source": [
    "## Lit Data Diagnostics\n",
    "Checking lit_direction_daily and daily_metrics for lit flow issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k73103rtnrf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check date range in lit_direction_daily (overall)\n",
    "print(\"=== Date range in lit_direction_daily ===\")\n",
    "display(conn.execute(\"\"\"\n",
    "    SELECT MIN(date) as min_date, MAX(date) as max_date, COUNT(*) as total_rows\n",
    "    FROM lit_direction_daily\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mklxtru62p",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Check which symbols have lit data\n",
    "print(\"=== Symbols with lit data (lit_direction_daily) ===\")\n",
    "display(conn.execute(\"\"\"\n",
    "    SELECT symbol, COUNT(*) as rows, MIN(date) as min_date, MAX(date) as max_date\n",
    "    FROM lit_direction_daily\n",
    "    GROUP BY symbol\n",
    "    ORDER BY rows DESC\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3zlxourla59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check lit_direction_daily for sample symbols (AAPL, SPY, XLF)\n",
    "print(\"=== Lit data for sample symbols ===\")\n",
    "for sym in [\"AAPL\", \"SPY\", \"XLF\"]:\n",
    "    print(f\"\\n--- {sym} ---\")\n",
    "    display(conn.execute(\"\"\"\n",
    "        SELECT date, lit_buy_volume, lit_sell_volume, lit_buy_ratio, log_buy_sell\n",
    "        FROM lit_direction_daily\n",
    "        WHERE symbol = ?\n",
    "        ORDER BY date DESC LIMIT 10\n",
    "    \"\"\", [sym]).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2xm0qsihn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check daily_metrics lit columns for sample symbols\n",
    "print(\"=== Daily_metrics lit columns for sample symbols ===\")\n",
    "for sym in [\"AAPL\", \"SPY\", \"XLF\"]:\n",
    "    print(f\"\\n--- {sym} ---\")\n",
    "    display(conn.execute(\"\"\"\n",
    "        SELECT date, lit_flow_imbalance, lit_buy_ratio, lit_buy_volume, lit_sell_volume\n",
    "        FROM daily_metrics\n",
    "        WHERE symbol = ?\n",
    "        ORDER BY date DESC LIMIT 10\n",
    "    \"\"\", [sym]).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "llbj9uppva",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compare config target_dates with DB date ranges\n",
    "print(\"=== Current config target_dates ===\")\n",
    "print(f\"Min: {min(config.target_dates)}, Max: {max(config.target_dates)}\")\n",
    "print(f\"Count: {len(config.target_dates)}\")\n",
    "\n",
    "print(\"\\n=== Overlap check: lit_direction_daily dates within target range ===\")\n",
    "display(conn.execute(\"\"\"\n",
    "    SELECT COUNT(*) as matching_rows\n",
    "    FROM lit_direction_daily\n",
    "    WHERE date >= ? AND date <= ?\n",
    "\"\"\", [min(config.target_dates), max(config.target_dates)]).df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cvv0vq1uqlc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Check polygon_ingestion_state (caching)\n",
    "print(\"=== Polygon ingestion state (cached trades) ===\")\n",
    "display(conn.execute(\"\"\"\n",
    "    SELECT symbol, data_source, COUNT(*) as cached_dates, \n",
    "           MIN(trade_date) as min_date, MAX(trade_date) as max_date\n",
    "    FROM polygon_ingestion_state\n",
    "    GROUP BY symbol, data_source\n",
    "    ORDER BY symbol\n",
    "\"\"\").df())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}