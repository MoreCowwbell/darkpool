{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0490f03",
   "metadata": {},
   "source": [
    "# Database Check\n",
    "Quick validation of database health after repopulation.\n",
    "\n",
    "| Cell | Description |\n",
    "|------|-------------|\n",
    "| 1 | Setup - imports and database connection |\n",
    "| 2 | Quick table overview with row counts |\n",
    "| 3 | Data Completeness - newest/oldest 5 days + NULL flagging |\n",
    "| 4 | Multi-Table Health Summary - freshness check |\n",
    "| 5 | Consolidated Sanity Checks - duplicates, invalid values |\n",
    "| 6 | Cleanup - close connection |\n",
    "\n",
    "**Usage:** Change `check_symbol` in Cell 3 to test different tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb86ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup - imports and database connection\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add darkpool root to path for darkpool_analysis imports\n",
    "darkpool_root = Path(__file__).parent.parent if '__file__' in dir() else Path.cwd().parent\n",
    "sys.path.insert(0, str(darkpool_root))\n",
    "\n",
    "from darkpool_analysis.config import load_config\n",
    "from darkpool_analysis.db import get_connection\n",
    "import pandas as pd\n",
    "\n",
    "config = load_config()\n",
    "conn = get_connection(config.db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Quick Table Overview - all tables with row counts\n",
    "from IPython.display import display\n",
    "\n",
    "overview = conn.execute(\"\"\"\n",
    "    SELECT name as table_name\n",
    "    FROM (SHOW TABLES)\n",
    "\"\"\").df()\n",
    "\n",
    "# Add row counts\n",
    "row_counts = []\n",
    "for tbl in overview['table_name']:\n",
    "    cnt = conn.execute(f\"SELECT COUNT(*) as n FROM {tbl}\").df()['n'].iloc[0]\n",
    "    row_counts.append(cnt)\n",
    "overview['rows'] = row_counts\n",
    "display(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q46lp1v2dso",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Data Completeness Check - newest/oldest 5 days with NULL field flagging\n",
    "\n",
    "check_symbol = \"AAPL\"  # Change to test different tickers\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"DATA COMPLETENESS CHECK FOR: {check_symbol}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Get newest 5 days\n",
    "print(\"\\nüìÖ NEWEST 5 DAYS (daily_metrics):\")\n",
    "newest = conn.execute(\"\"\"\n",
    "    SELECT * FROM daily_metrics\n",
    "    WHERE symbol = ?\n",
    "    ORDER BY date DESC\n",
    "    LIMIT 5\n",
    "\"\"\", [check_symbol]).df()\n",
    "display(newest)\n",
    "\n",
    "# Get oldest 5 days\n",
    "print(\"\\nüìÖ OLDEST 5 DAYS (daily_metrics):\")\n",
    "oldest = conn.execute(\"\"\"\n",
    "    SELECT * FROM daily_metrics\n",
    "    WHERE symbol = ?\n",
    "    ORDER BY date ASC\n",
    "    LIMIT 5\n",
    "\"\"\", [check_symbol]).df()\n",
    "display(oldest)\n",
    "\n",
    "# Combine for NULL analysis\n",
    "combined = pd.concat([newest, oldest], ignore_index=True)\n",
    "\n",
    "# Count NULLs per column\n",
    "print(\"\\nüîç NULL FIELD ANALYSIS (across newest + oldest 10 rows):\")\n",
    "null_counts = combined.isnull().sum()\n",
    "total_rows = len(combined)\n",
    "\n",
    "# Create summary dataframe\n",
    "null_summary = pd.DataFrame({\n",
    "    'column': null_counts.index,\n",
    "    'null_count': null_counts.values,\n",
    "    'total_rows': total_rows,\n",
    "    'null_pct': (null_counts.values / total_rows * 100).round(1),\n",
    "    'status': ['‚ö†Ô∏è MISSING' if n > 0 else '‚úÖ OK' for n in null_counts.values]\n",
    "})\n",
    "\n",
    "# Show only columns with issues first, then OK columns\n",
    "null_summary_sorted = null_summary.sort_values(['null_count', 'column'], ascending=[False, True])\n",
    "display(null_summary_sorted)\n",
    "\n",
    "# Summary flag\n",
    "missing_cols = null_summary[null_summary['null_count'] > 0]['column'].tolist()\n",
    "if missing_cols:\n",
    "    print(f\"\\n‚ö†Ô∏è  ALERT: {len(missing_cols)} columns have NULL values:\")\n",
    "    for col in missing_cols:\n",
    "        pct = null_summary[null_summary['column'] == col]['null_pct'].values[0]\n",
    "        print(f\"   - {col}: {pct}% null\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ALL FIELDS POPULATED - No NULL values detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7l17xupg8s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Multi-Table Data Health Summary - check all key tables for sample ticker\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MULTI-TABLE HEALTH CHECK FOR: {check_symbol}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define tables and their date columns\n",
    "table_checks = [\n",
    "    (\"daily_metrics\", \"date\", \"symbol\"),\n",
    "    (\"lit_direction_daily\", \"date\", \"symbol\"),\n",
    "    (\"finra_short_daily_raw\", \"trade_date\", \"symbol\"),\n",
    "    (\"polygon_daily_agg_raw\", \"trade_date\", \"symbol\"),\n",
    "]\n",
    "\n",
    "health_rows = []\n",
    "\n",
    "for table, date_col, sym_col in table_checks:\n",
    "    try:\n",
    "        result = conn.execute(f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as row_count,\n",
    "                MIN({date_col}) as oldest_date,\n",
    "                MAX({date_col}) as newest_date\n",
    "            FROM {table}\n",
    "            WHERE {sym_col} = ?\n",
    "        \"\"\", [check_symbol]).df()\n",
    "        \n",
    "        row_count = result['row_count'].iloc[0]\n",
    "        oldest = result['oldest_date'].iloc[0]\n",
    "        newest = result['newest_date'].iloc[0]\n",
    "        \n",
    "        # Check if newest date is within last 7 days\n",
    "        if newest and pd.Timestamp(newest) >= pd.Timestamp.now() - pd.Timedelta(days=7):\n",
    "            freshness = \"‚úÖ FRESH\"\n",
    "        elif newest:\n",
    "            freshness = \"‚ö†Ô∏è STALE\"\n",
    "        else:\n",
    "            freshness = \"‚ùå NO DATA\"\n",
    "            \n",
    "        health_rows.append({\n",
    "            'table': table,\n",
    "            'rows': row_count,\n",
    "            'oldest': oldest,\n",
    "            'newest': newest,\n",
    "            'freshness': freshness\n",
    "        })\n",
    "    except Exception as e:\n",
    "        health_rows.append({\n",
    "            'table': table,\n",
    "            'rows': 0,\n",
    "            'oldest': None,\n",
    "            'newest': None,\n",
    "            'freshness': f\"‚ùå ERROR: {str(e)[:30]}\"\n",
    "        })\n",
    "\n",
    "health_df = pd.DataFrame(health_rows)\n",
    "display(health_df)\n",
    "\n",
    "# Overall verdict\n",
    "stale_tables = health_df[health_df['freshness'].str.contains('STALE|ERROR|NO DATA', na=False)]['table'].tolist()\n",
    "if stale_tables:\n",
    "    print(f\"\\n‚ö†Ô∏è  ATTENTION: {len(stale_tables)} table(s) may need refresh:\")\n",
    "    for t in stale_tables:\n",
    "        print(f\"   - {t}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ALL TABLES HAVE FRESH DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Consolidated Sanity Checks - duplicates and invalid values\n",
    "print(f\"{'='*60}\")\n",
    "print(\"SANITY CHECKS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Check 1: Duplicate rows in daily_metrics\n",
    "print(\"\\nüîç Duplicate rows in daily_metrics:\")\n",
    "dupes_dm = conn.execute(\"\"\"\n",
    "    SELECT symbol, date, COUNT(*) AS n\n",
    "    FROM daily_metrics\n",
    "    GROUP BY symbol, date\n",
    "    HAVING n > 1\n",
    "\"\"\").df()\n",
    "if len(dupes_dm) == 0:\n",
    "    print(\"   ‚úÖ No duplicates found\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è {len(dupes_dm)} duplicate(s) found:\")\n",
    "    display(dupes_dm)\n",
    "\n",
    "# Check 2: Duplicate rows in lit_direction_daily\n",
    "print(\"\\nüîç Duplicate rows in lit_direction_daily:\")\n",
    "dupes_lit = conn.execute(\"\"\"\n",
    "    SELECT symbol, date, COUNT(*) AS n\n",
    "    FROM lit_direction_daily\n",
    "    GROUP BY symbol, date\n",
    "    HAVING n > 1\n",
    "\"\"\").df()\n",
    "if len(dupes_lit) == 0:\n",
    "    print(\"   ‚úÖ No duplicates found\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è {len(dupes_lit)} duplicate(s) found:\")\n",
    "    display(dupes_lit)\n",
    "\n",
    "# Check 3: Invalid short ratios (outside 0-1 range)\n",
    "print(\"\\nüîç Invalid short ratios (outside 0-1):\")\n",
    "bad_ratios = conn.execute(\"\"\"\n",
    "    SELECT symbol, date, short_ratio\n",
    "    FROM daily_metrics\n",
    "    WHERE short_ratio IS NOT NULL AND (short_ratio < 0 OR short_ratio > 1)\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "if len(bad_ratios) == 0:\n",
    "    print(\"   ‚úÖ All short ratios valid\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Invalid ratios found:\")\n",
    "    display(bad_ratios)\n",
    "\n",
    "# Check 4: Zero/negative lit volumes with non-null ratios\n",
    "print(\"\\nüîç Invalid lit volumes (zero/negative with computed ratio):\")\n",
    "bad_lit = conn.execute(\"\"\"\n",
    "    SELECT symbol, date, lit_buy_volume, lit_sell_volume\n",
    "    FROM lit_direction_daily\n",
    "    WHERE (lit_buy_volume <= 0 OR lit_sell_volume <= 0)\n",
    "      AND log_buy_sell IS NOT NULL\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "if len(bad_lit) == 0:\n",
    "    print(\"   ‚úÖ All lit volumes valid\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Invalid volumes found:\")\n",
    "    display(bad_lit)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jy4y65cxtba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Cleanup - close database connection\n",
    "conn.close()\n",
    "print(\"Database connection closed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
