{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 0 - Accumulation Signal Sandbox\n",
    "Explore alternate short-signal formulas using daily_metrics data (read-only). No database writes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a68c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tickers to process: ['META']\n",
      "Date range: 2025-12-01 to 2026-01-24\n",
      "Output directory: C:\\Users\\fvign\\Dropbox\\Vscode\\darkpool\\darkpool_analysis\\output\\WTD_VWBR\\2026-01-24\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 - Imports and Configuration\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_root = Path.cwd()\n",
    "if (project_root / 'darkpool_analysis').exists():\n",
    "    sys.path.insert(0, str(project_root))\n",
    "elif (project_root.parent / 'darkpool_analysis').exists():\n",
    "    sys.path.insert(0, str(project_root.parent))\n",
    "elif (project_root.parent.parent / 'darkpool_analysis').exists():\n",
    "    sys.path.insert(0, str(project_root.parent.parent))\n",
    "\n",
    "from darkpool_analysis.config import load_config, DAILY_EXPIRATION_TICKERS\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "# =============================================================================\n",
    "# TICKER CONFIGURATION\n",
    "# =============================================================================\n",
    "# By default, uses config.py's TICKERS_TYPE (shared with main.py)\n",
    "# Set TICKERS_OVERRIDE to a list to override, e.g., [\"SPY\", \"QQQ\", \"KRE\"]\n",
    "TICKERS_OVERRIDE = [\"META\"]  # None = use config.tickers\n",
    "\n",
    "# =============================================================================\n",
    "# DATE CONFIGURATION  \n",
    "# =============================================================================\n",
    "START_DATE = '2025-12-01'\n",
    "END_DATE = 'Today'  # 'Today' or 'YYYY-MM-DD' format\n",
    "\n",
    "# =============================================================================\n",
    "# OUTPUT CONFIGURATION\n",
    "# =============================================================================\n",
    "OUTPUT_BASE_DIR = config.output_dir / 'WTD_VWBR'\n",
    "DB_PATH = config.db_path\n",
    "\n",
    "# =============================================================================\n",
    "# BUY/SELL SIGNAL CONFIGURATION\n",
    "# =============================================================================\n",
    "BUY_SELL_SIGNAL = 'Rolling_Zscore'  # 'Mean_Threshold' or 'Rolling_Zscore'\n",
    "\n",
    "# Median-threshold settings\n",
    "THRESHOLD_K = 1.0       # default 1.0\n",
    "THRESHOLD_K_NEG = 1.0   # default 1.0\n",
    "\n",
    "# Rolling Z-score settings (used when BUY_SELL_SIGNAL = 'Rolling_Zscore')\n",
    "ROLLING_LOOKBACK_DAYS = 20  # extra history (days) to fetch for rolling calcs\n",
    "ROLLING_WINDOW_DAYS = 20\n",
    "ZSCORE_K_BUY = 1.1      # default 1.1, yearly runner up 1.8 \n",
    "ZSCORE_K_SELL = 1.1     # deafault 1.4, yearly runner up 1.5\n",
    "ZSCORE_MIN_PERIODS = 0  # defaults to ROLLING_WINDOW_DAYS\n",
    "\n",
    "# Rolling mean line settings (used when BUY_SELL_SIGNAL = 'Rolling_Zscore')\n",
    "ROLLING_MEAN_WINDOW_DAYS = ROLLING_WINDOW_DAYS\n",
    "ROLLING_MEAN_SHIFT_DAYS = 1  # use prior days for forward-valid mean\n",
    "\n",
    "# =============================================================================\n",
    "# OPTIONS PREMIUM CONFIGURATION\n",
    "# =============================================================================\n",
    "# Display modes: \"TOTAL\", \"WTD_STYLE\", \"FULL_BREAKDOWN\"\n",
    "# - TOTAL: Total call/put premium bars (backwards compatible)\n",
    "# - WTD_STYLE: OTM focus with ITM call hedge warning markers\n",
    "# - FULL_BREAKDOWN: Stacked bars showing OTM/ITM x Call/Put\n",
    "OPTIONS_PREMIUM_DISPLAY_MODE = \"FULL_BREAKDOWN\"\n",
    "\n",
    "# Enable/disable options premium panels\n",
    "SHOW_0DTE_PANEL = True   # Only shows for tickers in DAILY_EXPIRATION_TICKERS\n",
    "SHOW_WEEKLY_PANEL = True\n",
    "\n",
    "# ITM call hedge warning threshold (used in WTD_STYLE mode)\n",
    "ITM_CALL_HEDGE_THRESHOLD = 0.30  # 30%\n",
    "\n",
    "# =============================================================================\n",
    "# PLOT DISPLAY SETTINGS\n",
    "# =============================================================================\n",
    "# Text scaling for 30 days\n",
    "AUTO_TEXT_SCALE = True  # scale text with figure width\n",
    "BASE_FIG_WIDTH = 12.0\n",
    "TEXT_SCALE_MIN = 1.0\n",
    "TEXT_SCALE_MAX = 3.5\n",
    "TEXT_SCALE_POWER = 6  # exponent for width-based scaling\n",
    "\n",
    "# X-axis labeling\n",
    "MAX_X_LABELS = 90  # keep all labels up to this count\n",
    "\n",
    "# Figure sizing\n",
    "FIG_HEIGHT_RATIO = 1.0  # height = width * ratio\n",
    "FIG_DPI = 100\n",
    "FIGSIZE_PX = None  # None, or (width_px, height_px) to override\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def get_tickers(tickers_override: list | None = None) -> list:\n",
    "    \"\"\"Get tickers from config or use override if provided.\"\"\"\n",
    "    if tickers_override:\n",
    "        return tickers_override\n",
    "    return config.tickers\n",
    "\n",
    "def parse_end_date(end_date_str: str) -> str:\n",
    "    \"\"\"Parse END_DATE, supporting 'Today' keyword.\"\"\"\n",
    "    if end_date_str.lower() == 'today':\n",
    "        return pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "    return end_date_str\n",
    "\n",
    "def get_output_dir(base_dir: Path, end_date: str) -> Path:\n",
    "    \"\"\"Create and return dated output directory.\"\"\"\n",
    "    date_str = pd.to_datetime(end_date).strftime('%Y-%m-%d')\n",
    "    output_dir = base_dir / date_str\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return output_dir\n",
    "\n",
    "# Resolve configuration\n",
    "TICKERS = get_tickers(TICKERS_OVERRIDE)\n",
    "END_DATE_RESOLVED = parse_end_date(END_DATE)\n",
    "OUTPUT_DIR = get_output_dir(OUTPUT_BASE_DIR, END_DATE_RESOLVED)\n",
    "\n",
    "print(f\"Tickers to process: {TICKERS}\")\n",
    "print(f\"Date range: {START_DATE} to {END_DATE_RESOLVED}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4be1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Styling Constants and Helper Functions\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "COLORS = {\n",
    "    'background': '#0f0f10',\n",
    "    'panel_bg': '#141416',\n",
    "    'text': '#e6e6e6',\n",
    "    'text_muted': '#8b8b8b',\n",
    "    'grid': '#2a2a2d',\n",
    "    'white': '#ffffff',\n",
    "    'green': '#00ff88',\n",
    "    'red': '#ff6b6b',\n",
    "    'yellow': '#ffd700',\n",
    "    'cyan': '#00d4ff',\n",
    "    'orange': '#ff9f43',\n",
    "    'purple': '#b026ff',\n",
    "    'neutral': '#6b6b6b',\n",
    "    'blue': '#4aa3ff',\n",
    "    # Options premium colors (TOS style)\n",
    "    'call_premium': '#6478c8',   # Steel blue\n",
    "    'put_premium': '#cc0000',    # Deep red\n",
    "    # ITM/OTM breakdown colors\n",
    "    'otm_call': '#6478c8',       # Bright steel blue (OTM calls - bullish signal)\n",
    "    'itm_call': '#3d4a7a',       # Muted steel blue (ITM calls - hedge signal)\n",
    "    'otm_put': '#cc0000',        # Bright red (OTM puts - directional)\n",
    "    'itm_put': '#7a3d3d',        # Muted red (ITM puts)\n",
    "    'hedge_warning': '#ffd700',  # Yellow for ITM call hedge warning\n",
    "}\n",
    "GRID_ALPHA = 0.18\n",
    "OHLC_LINE_WIDTH = 1.2\n",
    "\n",
    "\n",
    "def _compute_fig_width(day_count):\n",
    "    if day_count <= 0:\n",
    "        return 12.0\n",
    "    buckets = int(np.ceil(day_count / 50))\n",
    "    return 12.0 * max(1, buckets)\n",
    "\n",
    "\n",
    "def _apply_axis_style(ax):\n",
    "    scale = globals().get('TEXT_SCALE', 1.0)\n",
    "    ax.set_facecolor(COLORS['panel_bg'])\n",
    "    ax.tick_params(colors=COLORS['text'], labelsize=9 * scale)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color(COLORS['grid'])\n",
    "    ax.spines['bottom'].set_color(COLORS['grid'])\n",
    "    ax.grid(True, alpha=GRID_ALPHA, color=COLORS['grid'], linestyle='--')\n",
    "\n",
    "\n",
    "def _apply_accum_axis_style(ax):\n",
    "    scale = globals().get('TEXT_SCALE', 1.0)\n",
    "    ax.set_facecolor(COLORS['panel_bg'])\n",
    "    ax.tick_params(colors=COLORS['text'], labelsize=9 * scale)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color(COLORS['grid'])\n",
    "    ax.spines['bottom'].set_color(COLORS['grid'])\n",
    "    ax.grid(True, axis='y', alpha=GRID_ALPHA, color=COLORS['grid'], linestyle='-')\n",
    "    ax.grid(False, axis='x')\n",
    "\n",
    "\n",
    "def _apply_options_axis_style(ax):\n",
    "    \"\"\"Apply axis styling for options premium panel.\"\"\"\n",
    "    scale = globals().get('TEXT_SCALE', 1.0)\n",
    "    ax.set_facecolor(COLORS['panel_bg'])\n",
    "    ax.tick_params(colors=COLORS['text'], labelsize=9 * scale)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_color(COLORS['grid'])\n",
    "    ax.spines['bottom'].set_color(COLORS['grid'])\n",
    "    ax.grid(True, axis='y', alpha=GRID_ALPHA, color=COLORS['grid'], linestyle='--')\n",
    "    ax.grid(False, axis='x')\n",
    "\n",
    "\n",
    "def _format_plain_int(value):\n",
    "    if pd.isna(value):\n",
    "        return 'NA'\n",
    "    return f'{value:,.0f}'.replace(',', '')\n",
    "\n",
    "\n",
    "def _plot_smooth_line(ax, x_values, values, color, valid_mask, linewidth=1.0, alpha=0.7, zorder=3, linestyle='-'):\n",
    "    \"\"\"Plot a smooth PCHIP-interpolated line through valid data points.\"\"\"\n",
    "    mask = np.asarray(valid_mask)\n",
    "    if mask.sum() >= 3:\n",
    "        valid_x = x_values[mask]\n",
    "        valid_values = values[mask]\n",
    "\n",
    "        if pd.api.types.is_datetime64_any_dtype(valid_x):\n",
    "            x_nums = mdates.date2num(pd.to_datetime(valid_x))\n",
    "            x_dense = np.linspace(x_nums.min(), x_nums.max(), 150)\n",
    "            x_smooth = np.unique(np.concatenate([x_nums, x_dense]))\n",
    "            interp = PchipInterpolator(x_nums, np.asarray(valid_values, dtype=float))\n",
    "            y_smooth = interp(x_smooth)\n",
    "            x_plot = mdates.num2date(x_smooth)\n",
    "        else:\n",
    "            x_nums = np.asarray(valid_x, dtype=float)\n",
    "            x_dense = np.linspace(x_nums.min(), x_nums.max(), 150)\n",
    "            x_smooth = np.unique(np.concatenate([x_nums, x_dense]))\n",
    "            interp = PchipInterpolator(x_nums, np.asarray(valid_values, dtype=float))\n",
    "            y_smooth = interp(x_smooth)\n",
    "            x_plot = x_smooth\n",
    "\n",
    "        ax.plot(\n",
    "            x_plot,\n",
    "            y_smooth,\n",
    "            color=color,\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha,\n",
    "            zorder=zorder,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "    else:\n",
    "        ax.plot(\n",
    "            x_values[mask],\n",
    "            values[mask],\n",
    "            color=color,\n",
    "            linewidth=linewidth,\n",
    "            alpha=alpha,\n",
    "            zorder=zorder,\n",
    "            linestyle=linestyle,\n",
    "        )\n",
    "\n",
    "\n",
    "def _nice_volume_ticks(max_val, target_ticks=6):\n",
    "    if max_val is None or max_val <= 0 or not np.isfinite(max_val):\n",
    "        return np.array([0.0, 1.0])\n",
    "    raw_step = max_val / max(target_ticks - 1, 1)\n",
    "    magnitude = 10 ** int(math.floor(math.log10(raw_step)))\n",
    "    while raw_step < magnitude:\n",
    "        magnitude /= 10\n",
    "    steps = [1, 2, 5, 10]\n",
    "    step = steps[0] * magnitude\n",
    "    for s in steps:\n",
    "        candidate = s * magnitude\n",
    "        if candidate <= raw_step:\n",
    "            step = candidate\n",
    "    top = math.ceil(max_val / step) * step\n",
    "    return np.arange(0, top + step, step)\n",
    "\n",
    "\n",
    "def _plot_ohlc_bars(ax, df_ohlc, x_indices):\n",
    "    \"\"\"Plot OHLC bars matching plotter_chart.py style.\"\"\"\n",
    "    bar_width = 0.6\n",
    "    half_width = bar_width / 2\n",
    "\n",
    "    for xi, (_, row) in zip(x_indices, df_ohlc.iterrows()):\n",
    "        open_ = row['open']\n",
    "        high = row['high']\n",
    "        low = row['low']\n",
    "        close = row['close']\n",
    "        if pd.isna(open_) or pd.isna(close) or pd.isna(high) or pd.isna(low):\n",
    "            continue\n",
    "        color = COLORS['blue'] if close >= open_ else COLORS['orange']\n",
    "        ax.vlines(xi, low, high, color=color, linewidth=OHLC_LINE_WIDTH, zorder=3)\n",
    "        ax.hlines(open_, xi - half_width, xi, color=color, linewidth=OHLC_LINE_WIDTH, zorder=3)\n",
    "        ax.hlines(close, xi, xi + half_width, color=color, linewidth=OHLC_LINE_WIDTH, zorder=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e9f5a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Data Loading Functions\n",
    "\n",
    "def fetch_options_premium_data(\n",
    "    ticker: str,\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    db_path: Path,\n",
    "    expiration_type: str,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Fetch options premium summary data for a ticker and expiration type.\n",
    "    \n",
    "    Args:\n",
    "        ticker: Stock symbol\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        db_path: Path to DuckDB database\n",
    "        expiration_type: \"0DTE\" or \"WEEKLY\"\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with columns: date, total_call_premium, total_put_premium,\n",
    "        net_premium, log_ratio, otm_call_premium, itm_call_premium,\n",
    "        otm_put_premium, itm_put_premium, directional_score\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "            trade_date AS date,\n",
    "            total_call_premium,\n",
    "            total_put_premium,\n",
    "            net_premium,\n",
    "            log_ratio,\n",
    "            strikes_count,\n",
    "            otm_call_premium,\n",
    "            itm_call_premium,\n",
    "            otm_put_premium,\n",
    "            itm_put_premium,\n",
    "            directional_score\n",
    "        FROM options_premium_summary\n",
    "        WHERE symbol = ? AND trade_date BETWEEN ? AND ? AND expiration_type = ?\n",
    "        ORDER BY trade_date\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with duckdb.connect(str(db_path), read_only=True) as conn:\n",
    "            df = conn.execute(query, [ticker.upper(), start_date, end_date, expiration_type]).df()\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not fetch {expiration_type} options data for {ticker}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if not df.empty:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        numeric_cols = [\n",
    "            'total_call_premium', 'total_put_premium', 'net_premium', 'log_ratio',\n",
    "            'otm_call_premium', 'itm_call_premium', 'otm_put_premium', 'itm_put_premium',\n",
    "            'directional_score'\n",
    "        ]\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_ticker_data(ticker: str, start_date: str, end_date: str, db_path: Path,\n",
    "                     rolling_lookback_days: int = 0,\n",
    "                     fetch_options: bool = True) -> tuple:\n",
    "    \"\"\"Load metrics, OHLC, and options premium data for a single ticker.\n",
    "    \n",
    "    Args:\n",
    "        ticker: Stock symbol\n",
    "        start_date: Start date (YYYY-MM-DD)\n",
    "        end_date: End date (YYYY-MM-DD)\n",
    "        db_path: Path to DuckDB database\n",
    "        rolling_lookback_days: Extra days to fetch for rolling calculations\n",
    "        fetch_options: Whether to fetch options premium data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (df, df_ohlc, options_0dte_df, options_weekly_df) DataFrames\n",
    "    \"\"\"\n",
    "    query_start_date = start_date\n",
    "    if rolling_lookback_days and int(rolling_lookback_days) > 0:\n",
    "        query_start_date = (pd.to_datetime(start_date) - pd.Timedelta(days=int(rolling_lookback_days))).strftime('%Y-%m-%d')\n",
    "\n",
    "    query = '''\n",
    "        SELECT\n",
    "            date,\n",
    "            symbol,\n",
    "            finra_buy_volume,\n",
    "            short_sell_volume,\n",
    "            short_buy_sell_ratio,\n",
    "            short_buy_sell_ratio_z,\n",
    "            lit_buy_volume,\n",
    "            lit_sell_volume,\n",
    "            lit_flow_imbalance,\n",
    "            lit_flow_imbalance_z,\n",
    "            return_z,\n",
    "            otc_participation_z,\n",
    "            confidence\n",
    "        FROM daily_metrics\n",
    "        WHERE symbol = ? AND date BETWEEN ? AND ?\n",
    "        ORDER BY date\n",
    "    '''\n",
    "\n",
    "    ohlc_query = '''\n",
    "        SELECT\n",
    "            trade_date AS date,\n",
    "            open,\n",
    "            high,\n",
    "            low,\n",
    "            close,\n",
    "            volume\n",
    "        FROM polygon_daily_agg_raw\n",
    "        WHERE symbol = ? AND trade_date BETWEEN ? AND ?\n",
    "        ORDER BY trade_date\n",
    "    '''\n",
    "\n",
    "    with duckdb.connect(str(db_path), read_only=True) as conn:\n",
    "        df = conn.execute(query, [ticker.upper(), query_start_date, end_date]).df()\n",
    "        df_ohlc = conn.execute(ohlc_query, [ticker.upper(), query_start_date, end_date]).df()\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f'No data found for {ticker} between {start_date} and {end_date}.')\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    if 'finra_buy_volume' in df.columns:\n",
    "        df['finra_buy_volume'] = pd.to_numeric(df['finra_buy_volume'], errors='coerce')\n",
    "\n",
    "    # Process OHLC data\n",
    "    if not df_ohlc.empty:\n",
    "        df_ohlc['date'] = pd.to_datetime(df_ohlc['date'])\n",
    "        for col in ['open', 'high', 'low', 'close', 'volume']:\n",
    "            if col in df_ohlc.columns:\n",
    "                df_ohlc[col] = pd.to_numeric(df_ohlc[col], errors='coerce')\n",
    "        # Merge OHLC with metrics on date\n",
    "        df = df.merge(df_ohlc, on='date', how='left')\n",
    "    else:\n",
    "        df['open'] = np.nan\n",
    "        df['high'] = np.nan\n",
    "        df['low'] = np.nan\n",
    "        df['close'] = np.nan\n",
    "        df['volume'] = np.nan\n",
    "    \n",
    "    # Fetch options premium data\n",
    "    options_0dte_df = pd.DataFrame()\n",
    "    options_weekly_df = pd.DataFrame()\n",
    "    \n",
    "    if fetch_options:\n",
    "        # Check if ticker supports 0DTE (indices only)\n",
    "        if ticker.upper() in DAILY_EXPIRATION_TICKERS:\n",
    "            options_0dte_df = fetch_options_premium_data(\n",
    "                ticker, start_date, end_date, db_path, \"0DTE\"\n",
    "            )\n",
    "        # All tickers can have weekly options\n",
    "        options_weekly_df = fetch_options_premium_data(\n",
    "            ticker, start_date, end_date, db_path, \"WEEKLY\"\n",
    "        )\n",
    "    \n",
    "    return df, df_ohlc, options_0dte_df, options_weekly_df\n",
    "\n",
    "\n",
    "def prepare_plot_data(df: pd.DataFrame, start_date: str, end_date: str) -> tuple:\n",
    "    \"\"\"Prepare data for plotting by filtering to date range and setting up masks.\n",
    "    \n",
    "    Args:\n",
    "        df: Full DataFrame with metrics and OHLC\n",
    "        start_date: Plot start date (YYYY-MM-DD)\n",
    "        end_date: Plot end date (YYYY-MM-DD)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (full_df, plot_df) DataFrames for full data and plot range\n",
    "    \"\"\"\n",
    "    full_df = df.sort_values('date').copy()\n",
    "    market_mask = full_df['close'].notna()\n",
    "    full_df = full_df.loc[market_mask].copy()\n",
    "    \n",
    "    if full_df.empty:\n",
    "        raise ValueError('No market days with OHLC data in the selected range.')\n",
    "    \n",
    "    plot_start = pd.to_datetime(start_date)\n",
    "    plot_end = pd.to_datetime(end_date)\n",
    "    plot_df = full_df[(full_df['date'] >= plot_start) & (full_df['date'] <= plot_end)].copy()\n",
    "    plot_df = plot_df.reset_index(drop=True)\n",
    "    \n",
    "    if plot_df.empty:\n",
    "        raise ValueError('No market days with OHLC data in the selected range.')\n",
    "    \n",
    "    if 'finra_buy_volume' not in plot_df.columns:\n",
    "        raise ValueError('finra_buy_volume missing from dataset.')\n",
    "    \n",
    "    full_df['vw_accum'] = pd.to_numeric(full_df['finra_buy_volume'], errors='coerce')\n",
    "    plot_df['vw_accum'] = pd.to_numeric(plot_df['finra_buy_volume'], errors='coerce')\n",
    "    \n",
    "    return full_df, plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107489c9",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MAIN LOOP - Process All Tickers\n# =============================================================================\nprint(f\"\\n{'='*60}\")\nprint(f\"Processing {len(TICKERS)} tickers\")\nprint(f\"Date range: {START_DATE} to {END_DATE_RESOLVED}\")\nprint(f\"Output: {OUTPUT_DIR}\")\nprint(f\"Options display mode: {OPTIONS_PREMIUM_DISPLAY_MODE}\")\nprint(f\"{'='*60}\\n\")\n\n# Build signal config from globals\nsignal_config = {\n    'buy_sell_signal': BUY_SELL_SIGNAL,\n    'threshold_k': THRESHOLD_K,\n    'threshold_k_neg': THRESHOLD_K_NEG,\n    'rolling_window_days': ROLLING_WINDOW_DAYS,\n    'zscore_k_buy': ZSCORE_K_BUY,\n    'zscore_k_sell': ZSCORE_K_SELL,\n    'zscore_min_periods': ZSCORE_MIN_PERIODS,\n    'rolling_mean_window_days': ROLLING_MEAN_WINDOW_DAYS,\n    'rolling_mean_shift_days': ROLLING_MEAN_SHIFT_DAYS,\n}\n\nplot_config = {\n    'auto_text_scale': AUTO_TEXT_SCALE,\n    'base_fig_width': BASE_FIG_WIDTH,\n    'text_scale_min': TEXT_SCALE_MIN,\n    'text_scale_max': TEXT_SCALE_MAX,\n    'text_scale_power': TEXT_SCALE_POWER,\n    'max_x_labels': MAX_X_LABELS,\n    'fig_height_ratio': FIG_HEIGHT_RATIO,\n    'fig_dpi': FIG_DPI,\n    'figsize_px': FIGSIZE_PX,\n}\n\nall_reports = []\nall_data_by_ticker = {}  # Store full_df per ticker for performance analysis\nsuccessful_tickers = []\nfailed_tickers = []\n\nfor ticker in TICKERS:\n    print(f\"\\n{'─'*40}\")\n    print(f\"Processing: {ticker}\")\n    print(f\"{'─'*40}\")\n    \n    try:\n        # Load data (including options premium)\n        lookback = ROLLING_LOOKBACK_DAYS if BUY_SELL_SIGNAL == 'Rolling_Zscore' else 0\n        df, df_ohlc, options_0dte_df, options_weekly_df = load_ticker_data(\n            ticker, START_DATE, END_DATE_RESOLVED, DB_PATH, lookback,\n            fetch_options=True\n        )\n        \n        # Report options data availability\n        if not options_0dte_df.empty:\n            print(f\"  0DTE options data: {len(options_0dte_df)} days\")\n        if not options_weekly_df.empty:\n            print(f\"  Weekly options data: {len(options_weekly_df)} days\")\n        \n        # Prepare plot data\n        full_df, plot_df = prepare_plot_data(df, START_DATE, END_DATE_RESOLVED)\n        \n        # Store full_df for performance analysis\n        all_data_by_ticker[ticker] = full_df.copy()\n        \n        # Generate plot with options panels\n        fig, report_df = plot_wtd_vwbr(\n            ticker, full_df, plot_df,\n            START_DATE, END_DATE_RESOLVED, OUTPUT_DIR,\n            signal_config=signal_config,\n            plot_config=plot_config,\n            options_0dte_df=options_0dte_df,\n            options_weekly_df=options_weekly_df,\n            options_display_mode=OPTIONS_PREMIUM_DISPLAY_MODE,\n            show_0dte_panel=SHOW_0DTE_PANEL,\n            show_weekly_panel=SHOW_WEEKLY_PANEL,\n            itm_call_hedge_threshold=ITM_CALL_HEDGE_THRESHOLD,\n        )\n        \n        # Display inline\n        plt.show()\n        \n        # Add ticker to report\n        if not report_df.empty:\n            report_df['ticker'] = ticker\n            all_reports.append(report_df)\n        \n        successful_tickers.append(ticker)\n        print(f\"  Saved: {OUTPUT_DIR / f'{ticker.lower()}_wtd_vwbr_{START_DATE}_{END_DATE_RESOLVED}.png'}\")\n        \n    except ValueError as e:\n        print(f\"  SKIPPED: {e}\")\n        failed_tickers.append((ticker, str(e)))\n        continue\n    except Exception as e:\n        print(f\"  ERROR: {e}\")\n        failed_tickers.append((ticker, str(e)))\n        continue\n\n# Summary\nprint(f\"\\n{'='*60}\")\nprint(\"PROCESSING COMPLETE\")\nprint(f\"{'='*60}\")\nprint(f\"Successful: {len(successful_tickers)} tickers\")\nprint(f\"Failed: {len(failed_tickers)} tickers\")\nif failed_tickers:\n    print(\"\\nFailed tickers:\")\n    for t, err in failed_tickers:\n        print(f\"  - {t}: {err}\")\nprint(f\"\\nOutput saved to: {OUTPUT_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "967990fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINED SIGNAL REPORT\n",
      "============================================================\n",
      "Total signals: 6\n",
      "  - BUY:  3\n",
      "  - SELL: 3\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-12-10</td>\n",
       "      <td>META</td>\n",
       "      <td>SELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-12-11</td>\n",
       "      <td>META</td>\n",
       "      <td>SELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-12</td>\n",
       "      <td>META</td>\n",
       "      <td>SELL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>META</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-22</td>\n",
       "      <td>META</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>META</td>\n",
       "      <td>BUY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker signal\n",
       "0  2025-12-10   META   SELL\n",
       "1  2025-12-11   META   SELL\n",
       "2  2025-12-12   META   SELL\n",
       "3  2026-01-13   META    BUY\n",
       "4  2026-01-22   META    BUY\n",
       "5  2026-01-23   META    BUY"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report saved to: C:\\Users\\fvign\\Dropbox\\Vscode\\darkpool\\darkpool_analysis\\output\\WTD_VWBR\\2026-01-24\\signal_report_2025-12-01_2026-01-24.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 5 - Combined Signal Report\n",
    "if 'all_reports' not in globals() or not all_reports:\n",
    "    print('No signals found across all processed tickers.')\n",
    "else:\n",
    "    combined_report = pd.concat(all_reports, ignore_index=True)\n",
    "    combined_report = combined_report.sort_values(['date', 'ticker'])\n",
    "    combined_report['date'] = combined_report['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"COMBINED SIGNAL REPORT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total signals: {len(combined_report)}\")\n",
    "    print(f\"  - BUY:  {(combined_report['signal'] == 'BUY').sum()}\")\n",
    "    print(f\"  - SELL: {(combined_report['signal'] == 'SELL').sum()}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    try:\n",
    "        display(combined_report[['date', 'ticker', 'signal']].reset_index(drop=True))\n",
    "    except NameError:\n",
    "        print(combined_report[['date', 'ticker', 'signal']].reset_index(drop=True))\n",
    "    \n",
    "    # Save combined report to CSV\n",
    "    report_path = OUTPUT_DIR / f\"signal_report_{START_DATE}_{END_DATE_RESOLVED}.csv\"\n",
    "    combined_report[['date', 'ticker', 'signal']].to_csv(report_path, index=False)\n",
    "    print(f\"\\nReport saved to: {report_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "nw02dajvh5e",
   "source": "# =============================================================================\n# PERFORMANCE MATRIX: Signal Cluster Analysis\n# =============================================================================\nfrom collections import defaultdict\n\ndef identify_clusters(report_df, signal_type, window_days=10):\n    \"\"\"\n    Identify clusters of same-direction signals within a rolling window.\n    \n    Returns list of clusters, each containing:\n    - signal_dates: list of dates in cluster\n    - cluster_size: number of signals\n    - entry_date: date of last signal (for next-open entry)\n    - ticker: the ticker symbol\n    \"\"\"\n    # Filter to signal type (BUY or SELL)\n    signals = report_df[report_df['signal'] == signal_type].copy()\n    if signals.empty:\n        return []\n    \n    # Convert date to datetime if string\n    if signals['date'].dtype == 'object':\n        signals['date'] = pd.to_datetime(signals['date'])\n    \n    signals = signals.sort_values('date').reset_index(drop=True)\n    \n    clusters = []\n    used_indices = set()\n    \n    for i in range(len(signals)):\n        if i in used_indices:\n            continue\n        \n        row = signals.iloc[i]\n        # Find all same-direction signals within window_days of this signal\n        cluster_dates = [row['date']]\n        cluster_indices = [i]\n        cluster_ticker = row['ticker']\n        \n        for j in range(i + 1, len(signals)):\n            if j in used_indices:\n                continue\n            next_row = signals.iloc[j]\n            next_date = next_row['date']\n            # Check if within window_days (calendar days) of the last signal in cluster\n            days_diff = (next_date - cluster_dates[-1]).days\n            if days_diff <= window_days and next_row['ticker'] == cluster_ticker:\n                cluster_dates.append(next_date)\n                cluster_indices.append(j)\n        \n        # Mark all as used\n        used_indices.update(cluster_indices)\n        \n        clusters.append({\n            'signal_dates': cluster_dates,\n            'cluster_size': len(cluster_dates),\n            'entry_date': cluster_dates[-1],  # Last signal date\n            'ticker': cluster_ticker\n        })\n    \n    return clusters\n\n\ndef calculate_forward_returns(entry_date, ticker_df, max_days=30):\n    \"\"\"\n    Calculate returns for days 1 through max_days after entry.\n    Entry = next session's open after entry_date.\n    Exit = close price at day N.\n    \n    Returns dict: {1: return_1d, 2: return_2d, ..., 30: return_30d}\n    \"\"\"\n    # Convert entry_date to same type as ticker_df['date']\n    if ticker_df['date'].dtype == 'datetime64[ns]':\n        if isinstance(entry_date, str):\n            entry_date = pd.to_datetime(entry_date)\n    \n    # Find entry index (next trading day after entry_date)\n    signal_mask = ticker_df['date'] == entry_date\n    if not signal_mask.any():\n        return {d: np.nan for d in range(1, max_days + 1)}\n    \n    signal_idx = ticker_df[signal_mask].index[0]\n    ticker_df_reset = ticker_df.reset_index(drop=True)\n    signal_pos = ticker_df_reset[ticker_df_reset['date'] == entry_date].index[0]\n    \n    entry_pos = signal_pos + 1\n    if entry_pos >= len(ticker_df_reset):\n        return {d: np.nan for d in range(1, max_days + 1)}\n    \n    entry_price = ticker_df_reset.loc[entry_pos, 'open']\n    if pd.isna(entry_price) or entry_price == 0:\n        return {d: np.nan for d in range(1, max_days + 1)}\n    \n    returns = {}\n    for day in range(1, max_days + 1):\n        exit_pos = entry_pos + day - 1  # day 1 = same day close\n        if exit_pos >= len(ticker_df_reset):\n            returns[day] = np.nan\n        else:\n            exit_price = ticker_df_reset.loc[exit_pos, 'close']\n            if pd.isna(exit_price):\n                returns[day] = np.nan\n            else:\n                returns[day] = (exit_price - entry_price) / entry_price * 100\n    \n    return returns\n\n\ndef build_performance_matrix(clusters, all_data_by_ticker, max_days=30):\n    \"\"\"\n    Build matrix: rows=cluster sizes, cols=forward days, values=avg returns.\n    \"\"\"\n    if not clusters:\n        return pd.DataFrame()\n    \n    # Group clusters by size\n    returns_by_size = defaultdict(list)\n    \n    for cluster in clusters:\n        size = cluster['cluster_size']\n        ticker = cluster['ticker']\n        \n        if ticker not in all_data_by_ticker:\n            continue\n            \n        ticker_df = all_data_by_ticker[ticker]\n        returns = calculate_forward_returns(cluster['entry_date'], ticker_df, max_days)\n        returns_by_size[size].append(returns)\n    \n    if not returns_by_size:\n        return pd.DataFrame()\n    \n    # Build matrix\n    max_size = max(returns_by_size.keys())\n    matrix_data = []\n    \n    for size in range(1, max_size + 1):\n        if size in returns_by_size:\n            # Average returns across all clusters of this size\n            all_returns = returns_by_size[size]\n            avg_returns = {}\n            for day in range(1, max_days + 1):\n                day_returns = [r[day] for r in all_returns if not pd.isna(r[day])]\n                avg_returns[day] = np.mean(day_returns) if day_returns else np.nan\n            matrix_data.append(avg_returns)\n        else:\n            # No clusters of this size - blank row\n            matrix_data.append({d: np.nan for d in range(1, max_days + 1)})\n    \n    # Convert to DataFrame\n    df = pd.DataFrame(matrix_data)\n    df.columns = [f'{d}d' for d in range(1, max_days + 1)]\n    df.index = [f'{i+1} signal{\"s\" if i > 0 else \"\"}' for i in range(len(df))]\n    \n    return df\n\n\ndef color_returns_cell(val):\n    \"\"\"Apply green/red gradient based on return value.\"\"\"\n    if pd.isna(val):\n        return 'background-color: #1a1a1d; color: #3a3a3d'  # Muted for N/A\n    \n    # Normalize intensity (cap at +/- 10% for gradient saturation)\n    intensity = min(abs(val) / 10, 1.0)\n    \n    if val > 0:\n        return f'background-color: rgba(0, 255, 136, {intensity * 0.5}); color: #00ff88'\n    elif val < 0:\n        return f'background-color: rgba(255, 68, 68, {intensity * 0.5}); color: #ff4444'\n    else:\n        return 'background-color: #1a1a1d; color: #e0e0e0'\n\n\ndef style_performance_matrix(df, title):\n    \"\"\"Apply full styling to performance matrix.\"\"\"\n    if df.empty:\n        return df\n    \n    styled = (df.style\n        .applymap(color_returns_cell)\n        .format(lambda x: f'{x:+.2f}%' if pd.notna(x) else '')\n        .set_properties(**{\n            'text-align': 'center',\n            'font-size': '11px',\n            'border': '1px solid #2a2a2d',\n            'padding': '4px 8px'\n        })\n        .set_table_styles([\n            {'selector': 'th', 'props': [\n                ('background-color', '#0f0f10'),\n                ('color', '#87ceeb'),\n                ('font-weight', 'bold'),\n                ('text-align', 'center'),\n                ('padding', '6px 8px')\n            ]},\n            {'selector': 'th.row_heading', 'props': [\n                ('background-color', '#0f0f10'),\n                ('color', '#e0e0e0'),\n                ('font-weight', 'bold')\n            ]},\n            {'selector': 'caption', 'props': [\n                ('color', '#87ceeb'),\n                ('font-size', '14px'),\n                ('font-weight', 'bold'),\n                ('padding', '10px')\n            ]}\n        ])\n        .set_caption(title)\n    )\n    return styled\n\n\n# Build performance matrices\nif 'combined_report' in globals() and not combined_report.empty and 'all_data_by_ticker' in globals():\n    # Identify clusters\n    buy_clusters = identify_clusters(combined_report, 'BUY', window_days=10)\n    sell_clusters = identify_clusters(combined_report, 'SELL', window_days=10)\n    \n    # Build matrices\n    buy_matrix = build_performance_matrix(buy_clusters, all_data_by_ticker, max_days=30)\n    sell_matrix = build_performance_matrix(sell_clusters, all_data_by_ticker, max_days=30)\n    \n    # Display BUY performance\n    print(f\"\\n{'='*60}\")\n    print(\"BUY CLUSTER PERFORMANCE\")\n    print(f\"{'='*60}\")\n    print(f\"Entry: Next open after last signal in cluster | Returns: Days 1-30\")\n    print(f\"Total BUY clusters: {len(buy_clusters)}\")\n    if not buy_matrix.empty:\n        display(style_performance_matrix(buy_matrix, 'BUY Signal Clusters - Average Forward Returns'))\n    else:\n        print(\"No BUY clusters found.\")\n    \n    # Display SELL performance\n    print(f\"\\n{'='*60}\")\n    print(\"SELL CLUSTER PERFORMANCE\")\n    print(f\"{'='*60}\")\n    print(f\"Entry: Next open after last signal in cluster | Returns: Days 1-30\")\n    print(f\"Total SELL clusters: {len(sell_clusters)}\")\n    if not sell_matrix.empty:\n        display(style_performance_matrix(sell_matrix, 'SELL Signal Clusters - Average Forward Returns'))\n    else:\n        print(\"No SELL clusters found.\")\nelse:\n    print(\"No signal data available for performance analysis.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d39de03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 6 - Backtest vs Buy-and-Hold (SPY/QQQ)\n",
    "# # Exit logic choices\n",
    "# BACKTEST_SYMBOLS = ['SPY', 'QQQ']\n",
    "# EXIT_MODE = 'next_signal'  # 'next_signal', 'fixed_hold', 'fixed_hold_or_opposite'\n",
    "# HOLD_DAYS = 7  # used for fixed-hold modes\n",
    "# ENTRY_DELAY_DAYS = 1  # apply signals on the next trading day\n",
    "# USE_SELL_SIGNALS = True\n",
    "# PLOT_BACKTEST = True\n",
    "\n",
    "# if 'plot_df' not in globals():\n",
    "#     raise ValueError('Run the plot cell first to populate plot_df and signals.')\n",
    "\n",
    "# if 'pos_idx' not in globals() or 'neg_idx' not in globals():\n",
    "#     accum = plot_df['vw_accum']\n",
    "#     valid_mask = ~accum.isna()\n",
    "#     full_accum_series = full_df.set_index('date')['vw_accum']\n",
    "#     full_valid_mask = ~full_accum_series.isna()\n",
    "#     pos_idx, neg_idx, _, _ = _compute_signal_indices(\n",
    "#         accum,\n",
    "#         valid_mask,\n",
    "#         full_accum_series=full_accum_series,\n",
    "#         full_valid_mask=full_valid_mask,\n",
    "#         plot_dates=plot_df['date'],\n",
    "#     )\n",
    "\n",
    "# plot_dates = plot_df['date']\n",
    "# buy_dates = plot_df.loc[pos_idx, 'date']\n",
    "# sell_dates = plot_df.loc[neg_idx, 'date']\n",
    "\n",
    "# signal_series = pd.Series(0, index=plot_dates)\n",
    "# signal_series.loc[buy_dates] = 1\n",
    "# if USE_SELL_SIGNALS:\n",
    "#     signal_series.loc[sell_dates] = -1\n",
    "# signal_series = signal_series.sort_index()\n",
    "# signal_trade = signal_series.shift(int(ENTRY_DELAY_DAYS)).fillna(0)\n",
    "\n",
    "# def _build_position_next_signal(signal):\n",
    "#     pos = []\n",
    "#     current = 0\n",
    "#     for sig in signal:\n",
    "#         if sig == 1:\n",
    "#             current = 1\n",
    "#         elif sig == -1:\n",
    "#             current = 0\n",
    "#         pos.append(current)\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _build_position_fixed_hold(signal, hold_days, exit_on_opposite):\n",
    "#     hold_days = max(int(hold_days), 1)\n",
    "#     pos = pd.Series(0, index=signal.index)\n",
    "#     days_left = 0\n",
    "#     for i, sig in enumerate(signal):\n",
    "#         if days_left > 0:\n",
    "#             if exit_on_opposite and sig == -1:\n",
    "#                 days_left = 0\n",
    "#                 pos.iloc[i] = 0\n",
    "#             else:\n",
    "#                 pos.iloc[i] = 1\n",
    "#                 days_left -= 1\n",
    "#             continue\n",
    "#         if sig == 1:\n",
    "#             pos.iloc[i] = 1\n",
    "#             days_left = hold_days - 1\n",
    "#     return pos\n",
    "\n",
    "# def _position_from_exit_mode(signal):\n",
    "#     if EXIT_MODE == 'next_signal':\n",
    "#         return _build_position_next_signal(signal)\n",
    "#     if EXIT_MODE == 'fixed_hold':\n",
    "#         return _build_position_fixed_hold(signal, HOLD_DAYS, exit_on_opposite=False)\n",
    "#     if EXIT_MODE == 'fixed_hold_or_opposite':\n",
    "#         return _build_position_fixed_hold(signal, HOLD_DAYS, exit_on_opposite=True)\n",
    "#     raise ValueError(f'Unknown EXIT_MODE: {EXIT_MODE}')\n",
    "\n",
    "# def _max_drawdown(equity_curve):\n",
    "#     running_max = equity_curve.cummax()\n",
    "#     drawdown = equity_curve / running_max - 1.0\n",
    "#     return drawdown.min()\n",
    "\n",
    "# def _backtest_symbol(symbol, signal):\n",
    "#     query = '''\n",
    "#         SELECT\n",
    "#             trade_date AS date,\n",
    "#             close\n",
    "#         FROM polygon_daily_agg_raw\n",
    "#         WHERE symbol = ? AND trade_date BETWEEN ? AND ?\n",
    "#         ORDER BY trade_date\n",
    "#     '''\n",
    "#     with duckdb.connect(str(DB_PATH), read_only=True) as conn:\n",
    "#         price_df = conn.execute(query, [symbol, START_DATE, END_DATE]).df()\n",
    "\n",
    "#     if price_df.empty:\n",
    "#         raise ValueError(f'No price data found for {symbol} between {START_DATE} and {END_DATE}.')\n",
    "\n",
    "#     price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "#     price_df['close'] = pd.to_numeric(price_df['close'], errors='coerce')\n",
    "#     price_df = price_df.dropna(subset=['close'])\n",
    "#     price_df = price_df.set_index('date').reindex(signal.index).dropna()\n",
    "\n",
    "#     aligned_signal = signal.reindex(price_df.index).fillna(0)\n",
    "#     position = _position_from_exit_mode(aligned_signal)\n",
    "\n",
    "#     returns = price_df['close'].pct_change().fillna(0)\n",
    "#     strat_equity = (1.0 + returns * position).cumprod()\n",
    "#     bh_equity = (1.0 + returns).cumprod()\n",
    "\n",
    "#     years = len(strat_equity) / 252.0\n",
    "#     strat_cagr = strat_equity.iloc[-1] ** (1.0 / years) - 1.0 if years > 0 else np.nan\n",
    "#     bh_cagr = bh_equity.iloc[-1] ** (1.0 / years) - 1.0 if years > 0 else np.nan\n",
    "\n",
    "#     summary = {\n",
    "#         'symbol': symbol,\n",
    "#         'strategy_total_return': strat_equity.iloc[-1] - 1.0,\n",
    "#         'strategy_cagr': strat_cagr,\n",
    "#         'strategy_max_dd': _max_drawdown(strat_equity),\n",
    "#         'buy_hold_total_return': bh_equity.iloc[-1] - 1.0,\n",
    "#         'buy_hold_cagr': bh_cagr,\n",
    "#         'buy_hold_max_dd': _max_drawdown(bh_equity),\n",
    "#     }\n",
    "#     return summary, strat_equity, bh_equity\n",
    "\n",
    "# results = []\n",
    "# equity_curves = {}\n",
    "# for symbol in BACKTEST_SYMBOLS:\n",
    "#     summary, strat_eq, bh_eq = _backtest_symbol(symbol, signal_trade)\n",
    "#     results.append(summary)\n",
    "#     equity_curves[symbol] = (strat_eq, bh_eq)\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# display(results_df)\n",
    "\n",
    "# if PLOT_BACKTEST:\n",
    "#     fig, axes = plt.subplots(len(BACKTEST_SYMBOLS), 1, figsize=(10, 3 * len(BACKTEST_SYMBOLS)), sharex=True)\n",
    "#     if len(BACKTEST_SYMBOLS) == 1:\n",
    "#         axes = [axes]\n",
    "#     for ax, symbol in zip(axes, BACKTEST_SYMBOLS):\n",
    "#         strat_eq, bh_eq = equity_curves[symbol]\n",
    "#         ax.plot(strat_eq.index, strat_eq.values, label='Signal Strategy', color='#00d4ff')\n",
    "#         ax.plot(bh_eq.index, bh_eq.values, label='Buy & Hold', color='#ffffff', alpha=0.7)\n",
    "#         ax.set_title(f'{symbol} Backtest', fontsize=10)\n",
    "#         ax.grid(True, linestyle='--', alpha=0.3)\n",
    "#         ax.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28c5c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 7 - Parameter Sweep (Rolling Z-Score)\n",
    "# # Long-only: buy on BUY signal; sell on SELL signal.\n",
    "# # Position modes:\n",
    "# # - buy_every_signal: add 1 unit on every BUY, reset to 0 on SELL (unlimited capital).\n",
    "# # - ignore_while_long: enter once, ignore extra BUYs until SELL.\n",
    "# # - average_down_only: add 1 unit only when price < avg entry price.\n",
    "\n",
    "# ROLLING_WINDOW_DAYS_LIST = [20, 40, 60]\n",
    "# ZSCORE_K_BUY_LIST = [round(x, 1) for x in np.arange(1.0, 1.8 + 0.001, 0.1)]\n",
    "# ZSCORE_K_SELL_LIST = [round(x, 1) for x in np.arange(1.0, 1.8 + 0.001, 0.1)]\n",
    "# ENTRY_DELAY_DAYS_LIST = list(range(1, 11))\n",
    "# POSITION_MODES = ['buy_every_signal', 'ignore_while_long', 'average_down_only']\n",
    "# MAX_UNITS_CAP_LIST = [1, 3, 5, 10]  # None = unlimited (only used for average_down_only)\n",
    "# MAX_DD_EXIT_LIST = [None]  # Per-trade stop-loss: [0.20] for 20%, [None] to disable\n",
    "# PORTFOLIO_MAX_DD_LIST = [0.10, 0.15, 0.20]  # Overall portfolio drawdown cap: [0.20] for 20%\n",
    "# BACKTEST_SYMBOLS = ['QQQ']\n",
    "# SHOW_TOP_N = 20\n",
    "# SORT_METRIC = 'strategy_cagr'  # options: strategy_total_return, strategy_cagr, strategy_max_dd\n",
    "# RISK_FREE_RATE = 0.0  # annual risk-free rate for Sharpe\n",
    "# TRADING_DAYS = 252\n",
    "\n",
    "# if 'plot_df' not in globals() or 'full_df' not in globals():\n",
    "#     raise ValueError('Run the plot cell first to populate plot_df/full_df.')\n",
    "\n",
    "# plot_dates = plot_df['date']\n",
    "# full_accum_series = full_df.set_index('date')['vw_accum']\n",
    "# full_valid_mask = ~full_accum_series.isna()\n",
    "\n",
    "# # Calculate combo count\n",
    "# other_modes_count = len([m for m in POSITION_MODES if m != 'average_down_only'])\n",
    "# avg_down_runs = len(MAX_UNITS_CAP_LIST) if 'average_down_only' in POSITION_MODES else 0\n",
    "# combo_count = (\n",
    "#     len(ROLLING_WINDOW_DAYS_LIST)\n",
    "#     * len(ZSCORE_K_BUY_LIST)\n",
    "#     * len(ZSCORE_K_SELL_LIST)\n",
    "#     * len(ENTRY_DELAY_DAYS_LIST)\n",
    "#     * (other_modes_count + avg_down_runs)\n",
    "#     * len(MAX_DD_EXIT_LIST)\n",
    "#     * len(PORTFOLIO_MAX_DD_LIST)\n",
    "#     * len(BACKTEST_SYMBOLS)\n",
    "# )\n",
    "\n",
    "# # Print strategy explanation header\n",
    "# print('=' * 70)\n",
    "# print('PARAMETER SWEEP - Rolling Z-Score Strategy')\n",
    "# print('=' * 70)\n",
    "# print('Entry Signal:  BUY when Z-score >= +K_buy')\n",
    "# print('Exit Signal:   SELL when Z-score <= -K_sell (closes all positions)')\n",
    "# print('               OR per-trade max drawdown hit (if enabled)')\n",
    "# print('               OR portfolio max drawdown hit (stops all trading)')\n",
    "# print('-' * 70)\n",
    "# print('Position Modes:')\n",
    "# print('  - buy_every_signal:   Pyramid into position (add 1 unit per BUY)')\n",
    "# print('  - ignore_while_long:  Single entry (ignore BUYs while long)')\n",
    "# print('  - average_down_only:  Add only when price < avg entry')\n",
    "# print('-' * 70)\n",
    "# print(f'Per-Trade DD Exit:    {[f\"{x:.0%}\" if x else \"None\" for x in MAX_DD_EXIT_LIST]}')\n",
    "# print(f'Portfolio DD Cap:     {[f\"{x:.0%}\" if x else \"None\" for x in PORTFOLIO_MAX_DD_LIST]}')\n",
    "# print(f'Parameter sweep size: {combo_count} runs')\n",
    "# print('=' * 70)\n",
    "# print()\n",
    "\n",
    "# def _max_drawdown(equity_curve):\n",
    "#     running_max = equity_curve.cummax()\n",
    "#     drawdown = equity_curve / running_max - 1.0\n",
    "#     return drawdown.min()\n",
    "\n",
    "# def _build_position_buy_every(signal, prices=None, max_dd_exit=None):\n",
    "#     \"\"\"Build position with pyramiding. Optional max drawdown exit.\"\"\"\n",
    "#     pos = []\n",
    "#     units = 0\n",
    "#     peak_value = 0.0\n",
    "#     entry_prices = []\n",
    "\n",
    "#     for i, sig in enumerate(signal):\n",
    "#         price = prices.iloc[i] if prices is not None else None\n",
    "        \n",
    "#         if sig == 1:\n",
    "#             units += 1\n",
    "#             if price is not None:\n",
    "#                 entry_prices.append(price)\n",
    "#                 peak_value = sum(price for _ in entry_prices)\n",
    "#         elif sig == -1:\n",
    "#             units = 0\n",
    "#             peak_value = 0.0\n",
    "#             entry_prices = []\n",
    "        \n",
    "#         if units > 0 and max_dd_exit is not None and price is not None and len(entry_prices) > 0:\n",
    "#             current_value = units * price\n",
    "#             peak_value = max(peak_value, current_value)\n",
    "#             if peak_value > 0:\n",
    "#                 dd_from_peak = (current_value - peak_value) / peak_value\n",
    "#                 if dd_from_peak <= -max_dd_exit:\n",
    "#                     units = 0\n",
    "#                     peak_value = 0.0\n",
    "#                     entry_prices = []\n",
    "        \n",
    "#         pos.append(units)\n",
    "\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _build_position_ignore_long(signal, prices=None, max_dd_exit=None):\n",
    "#     \"\"\"Build position with single entry. Optional max drawdown exit.\"\"\"\n",
    "#     pos = []\n",
    "#     current = 0\n",
    "#     entry_price = None\n",
    "#     peak_value = 0.0\n",
    "\n",
    "#     for i, sig in enumerate(signal):\n",
    "#         price = prices.iloc[i] if prices is not None else None\n",
    "        \n",
    "#         if sig == 1:\n",
    "#             if current == 0:\n",
    "#                 current = 1\n",
    "#                 entry_price = price\n",
    "#                 peak_value = price if price else 0.0\n",
    "#         elif sig == -1:\n",
    "#             current = 0\n",
    "#             entry_price = None\n",
    "#             peak_value = 0.0\n",
    "        \n",
    "#         if current > 0 and max_dd_exit is not None and price is not None and peak_value > 0:\n",
    "#             peak_value = max(peak_value, price)\n",
    "#             dd_from_peak = (price - peak_value) / peak_value\n",
    "#             if dd_from_peak <= -max_dd_exit:\n",
    "#                 current = 0\n",
    "#                 entry_price = None\n",
    "#                 peak_value = 0.0\n",
    "        \n",
    "#         pos.append(current)\n",
    "\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _build_position_average_down_only(signal, prices, max_units=None, max_dd_exit=None):\n",
    "#     \"\"\"Enter on first BUY, add only when price < average entry price.\"\"\"\n",
    "#     pos = []\n",
    "#     units = 0\n",
    "#     total_cost = 0.0\n",
    "#     peak_value = 0.0\n",
    "\n",
    "#     for i, (sig, price) in enumerate(zip(signal, prices)):\n",
    "#         if sig == 1:\n",
    "#             if units == 0:\n",
    "#                 units = 1\n",
    "#                 total_cost = price\n",
    "#                 peak_value = price\n",
    "#             else:\n",
    "#                 avg_entry_price = total_cost / units\n",
    "#                 can_add = (max_units is None) or (units < max_units)\n",
    "#                 if price < avg_entry_price and can_add:\n",
    "#                     units += 1\n",
    "#                     total_cost += price\n",
    "#         elif sig == -1:\n",
    "#             units = 0\n",
    "#             total_cost = 0.0\n",
    "#             peak_value = 0.0\n",
    "\n",
    "#         if units > 0 and max_dd_exit is not None and peak_value > 0:\n",
    "#             current_value = units * price\n",
    "#             peak_value = max(peak_value, current_value)\n",
    "#             dd_from_peak = (current_value - peak_value) / peak_value\n",
    "#             if dd_from_peak <= -max_dd_exit:\n",
    "#                 units = 0\n",
    "#                 total_cost = 0.0\n",
    "#                 peak_value = 0.0\n",
    "\n",
    "#         pos.append(units)\n",
    "\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _apply_portfolio_dd_cap(position, returns, portfolio_max_dd):\n",
    "#     \"\"\"\n",
    "#     Apply portfolio-level drawdown cap.\n",
    "#     Once equity drops portfolio_max_dd from peak, go flat and stay flat.\n",
    "#     \"\"\"\n",
    "#     if portfolio_max_dd is None:\n",
    "#         return position\n",
    "    \n",
    "#     capped_pos = position.copy()\n",
    "#     equity = 1.0\n",
    "#     peak_equity = 1.0\n",
    "#     stopped_out = False\n",
    "    \n",
    "#     for i, (pos, ret) in enumerate(zip(position, returns)):\n",
    "#         if stopped_out:\n",
    "#             capped_pos.iloc[i] = 0\n",
    "#             continue\n",
    "        \n",
    "#         # Calculate equity after this day's return\n",
    "#         equity = equity * (1.0 + ret * pos)\n",
    "#         peak_equity = max(peak_equity, equity)\n",
    "        \n",
    "#         # Check if portfolio drawdown exceeded\n",
    "#         if peak_equity > 0:\n",
    "#             portfolio_dd = (equity - peak_equity) / peak_equity\n",
    "#             if portfolio_dd <= -portfolio_max_dd:\n",
    "#                 stopped_out = True\n",
    "#                 capped_pos.iloc[i] = 0  # Exit immediately\n",
    "    \n",
    "#     return capped_pos\n",
    "\n",
    "# def _load_price_series(symbol):\n",
    "#     query = '''\n",
    "#         SELECT\n",
    "#             trade_date AS date,\n",
    "#             close\n",
    "#         FROM polygon_daily_agg_raw\n",
    "#         WHERE symbol = ? AND trade_date BETWEEN ? AND ?\n",
    "#         ORDER BY trade_date\n",
    "#     '''\n",
    "#     with duckdb.connect(str(DB_PATH), read_only=True) as conn:\n",
    "#         price_df = conn.execute(query, [symbol, START_DATE, END_DATE]).df()\n",
    "#     if price_df.empty:\n",
    "#         raise ValueError(f'No price data found for {symbol} between {START_DATE} and {END_DATE}.')\n",
    "#     price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "#     price_df['close'] = pd.to_numeric(price_df['close'], errors='coerce')\n",
    "#     price_df = price_df.dropna(subset=['close']).set_index('date')\n",
    "#     price_df = price_df.reindex(plot_dates).dropna()\n",
    "#     return price_df['close']\n",
    "\n",
    "# price_series = {symbol: _load_price_series(symbol) for symbol in BACKTEST_SYMBOLS}\n",
    "# returns_series = {symbol: series.pct_change().fillna(0) for symbol, series in price_series.items()}\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for window in ROLLING_WINDOW_DAYS_LIST:\n",
    "#     min_periods = window if ZSCORE_MIN_PERIODS is None else int(ZSCORE_MIN_PERIODS)\n",
    "#     prior = full_accum_series.shift(1)\n",
    "#     rolling_mean = prior.rolling(window=int(window), min_periods=min_periods).mean()\n",
    "#     rolling_std = prior.rolling(window=int(window), min_periods=min_periods).std(ddof=0)\n",
    "#     z_scores = (full_accum_series - rolling_mean) / rolling_std\n",
    "#     ok_mask = full_valid_mask & rolling_mean.notna() & rolling_std.notna() & (rolling_std > 0)\n",
    "\n",
    "#     for z_buy in ZSCORE_K_BUY_LIST:\n",
    "#         for z_sell in ZSCORE_K_SELL_LIST:\n",
    "#             pos_mask = ok_mask & (z_scores >= z_buy)\n",
    "#             neg_mask = ok_mask & (z_scores <= -z_sell)\n",
    "#             pos_dates = full_accum_series[pos_mask].index\n",
    "#             neg_dates = full_accum_series[neg_mask].index\n",
    "\n",
    "#             buy_dates = plot_dates[plot_dates.isin(pos_dates)]\n",
    "#             sell_dates = plot_dates[plot_dates.isin(neg_dates)]\n",
    "\n",
    "#             base_signal = pd.Series(0, index=plot_dates)\n",
    "#             base_signal.loc[buy_dates] = 1\n",
    "#             base_signal.loc[sell_dates] = -1\n",
    "#             base_signal = base_signal.sort_index()\n",
    "\n",
    "#             for entry_delay in ENTRY_DELAY_DAYS_LIST:\n",
    "#                 signal_trade = base_signal.shift(int(entry_delay)).fillna(0)\n",
    "\n",
    "#                 for max_dd_exit in MAX_DD_EXIT_LIST:\n",
    "#                     for portfolio_max_dd in PORTFOLIO_MAX_DD_LIST:\n",
    "#                         for mode in POSITION_MODES:\n",
    "#                             if mode == 'average_down_only':\n",
    "#                                 cap_iterations = MAX_UNITS_CAP_LIST\n",
    "#                             else:\n",
    "#                                 cap_iterations = [None]\n",
    "\n",
    "#                             for max_cap in cap_iterations:\n",
    "#                                 for symbol in BACKTEST_SYMBOLS:\n",
    "#                                     prices_aligned = price_series[symbol].reindex(signal_trade.index).ffill()\n",
    "                                    \n",
    "#                                     if mode == 'buy_every_signal':\n",
    "#                                         position = _build_position_buy_every(\n",
    "#                                             signal_trade, prices_aligned, max_dd_exit=max_dd_exit\n",
    "#                                         )\n",
    "#                                         max_units_used = 'N/A'\n",
    "#                                     elif mode == 'ignore_while_long':\n",
    "#                                         position = _build_position_ignore_long(\n",
    "#                                             signal_trade, prices_aligned, max_dd_exit=max_dd_exit\n",
    "#                                         )\n",
    "#                                         max_units_used = 'N/A'\n",
    "#                                     elif mode == 'average_down_only':\n",
    "#                                         position = _build_position_average_down_only(\n",
    "#                                             signal_trade, prices_aligned, \n",
    "#                                             max_units=max_cap, max_dd_exit=max_dd_exit\n",
    "#                                         )\n",
    "#                                         max_units_used = max_cap if max_cap else 'unlimited'\n",
    "#                                     else:\n",
    "#                                         raise ValueError(f'Unknown position mode: {mode}')\n",
    "\n",
    "#                                     returns = returns_series[symbol].reindex(position.index).fillna(0)\n",
    "                                    \n",
    "#                                     # Apply portfolio-level drawdown cap\n",
    "#                                     position = _apply_portfolio_dd_cap(position, returns, portfolio_max_dd)\n",
    "                                    \n",
    "#                                     daily_mean = returns.mean()\n",
    "#                                     daily_std = returns.std(ddof=0)\n",
    "#                                     ann_vol = daily_std * (TRADING_DAYS ** 0.5) if daily_std > 0 else np.nan\n",
    "#                                     ann_return = daily_mean * TRADING_DAYS\n",
    "#                                     sharpe = ((ann_return - RISK_FREE_RATE) / ann_vol) if ann_vol and ann_vol > 0 else np.nan\n",
    "#                                     equity = (1.0 + returns * position).cumprod()\n",
    "#                                     years = len(equity) / 252.0\n",
    "#                                     cagr = equity.iloc[-1] ** (1.0 / years) - 1.0 if years > 0 else np.nan\n",
    "                                    \n",
    "#                                     max_dd_str = f\"{max_dd_exit:.0%}\" if max_dd_exit else 'None'\n",
    "#                                     portfolio_dd_str = f\"{portfolio_max_dd:.0%}\" if portfolio_max_dd else 'None'\n",
    "                                    \n",
    "#                                     summary = {\n",
    "#                                         'symbol': symbol,\n",
    "#                                         'entry_mode': mode,\n",
    "#                                         'exit_strategy': 'on_sell_signal',\n",
    "#                                         'trade_dd_exit': max_dd_str,\n",
    "#                                         'portfolio_dd_cap': portfolio_dd_str,\n",
    "#                                         'max_units_cap': max_units_used,\n",
    "#                                         'rolling_window': window,\n",
    "#                                         'k_buy': z_buy,\n",
    "#                                         'k_sell': z_sell,\n",
    "#                                         'entry_delay': entry_delay,\n",
    "#                                         'total_return': equity.iloc[-1] - 1.0,\n",
    "#                                         'cagr': cagr,\n",
    "#                                         'max_dd': _max_drawdown(equity),\n",
    "#                                         'ann_vol': ann_vol,\n",
    "#                                         'sharpe': sharpe,\n",
    "#                                     }\n",
    "#                                     results.append(summary)\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# if results_df.empty:\n",
    "#     print('No results produced. Check inputs and data availability.')\n",
    "# else:\n",
    "#     sort_col = SORT_METRIC.replace('strategy_', '').replace('_days', '')\n",
    "#     if sort_col not in results_df.columns:\n",
    "#         sort_col = 'cagr'\n",
    "#     results_df = results_df.sort_values(sort_col, ascending=(sort_col == 'max_dd'))\n",
    "    \n",
    "#     print(f'Top {SHOW_TOP_N} results (sorted by {sort_col}):')\n",
    "#     print()\n",
    "#     try:\n",
    "#         display(results_df.head(SHOW_TOP_N).reset_index(drop=True))\n",
    "#     except NameError:\n",
    "#         print(results_df.head(SHOW_TOP_N).reset_index(drop=True))\n",
    "    \n",
    "#     print()\n",
    "#     print('=' * 70)\n",
    "#     print(f'BEST SETTINGS (by {sort_col}):')\n",
    "#     print('=' * 70)\n",
    "#     best_row = results_df.iloc[0]\n",
    "#     print(f\"  Symbol:           {best_row['symbol']}\")\n",
    "#     print(f\"  Entry Mode:       {best_row['entry_mode']}\")\n",
    "#     print(f\"  Exit Strategy:    {best_row['exit_strategy']}\")\n",
    "#     print(f\"  Trade DD Exit:    {best_row['trade_dd_exit']} (per-trade stop-loss)\")\n",
    "#     print(f\"  Portfolio DD Cap: {best_row['portfolio_dd_cap']} (overall cap)\")\n",
    "#     print(f\"  Max Units Cap:    {best_row['max_units_cap']}\")\n",
    "#     print(f\"  Rolling Window:   {best_row['rolling_window']} days\")\n",
    "#     print(f\"  K Buy:            +{best_row['k_buy']:.1f} (Z-score threshold)\")\n",
    "#     print(f\"  K Sell:           -{best_row['k_sell']:.1f} (Z-score threshold)\")\n",
    "#     print(f\"  Entry Delay:      {best_row['entry_delay']} days\")\n",
    "#     print('-' * 70)\n",
    "#     print(f\"  Total Return:     {best_row['total_return']:+.2%}\")\n",
    "#     print(f\"  CAGR:             {best_row['cagr']:+.2%}\")\n",
    "#     print(f\"  Max Drawdown:     {best_row['max_dd']:.2%}\")\n",
    "#     print(f\"  Ann. Vol:         {best_row['ann_vol']:.2%}\")\n",
    "#     print(f\"  Sharpe Ratio:     {best_row['sharpe']:.2f}\")\n",
    "#     print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2aee902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cell 8 - Plot Best Settings vs Buy-and-Hold (QQQ/SPY)\n",
    "# if 'results_df' not in globals() or results_df.empty:\n",
    "#     raise ValueError('Run the parameter sweep cell first to produce results_df.')\n",
    "\n",
    "# best_row = results_df.iloc[0]\n",
    "# best_window = int(best_row['rolling_window'])\n",
    "# best_k_buy = float(best_row['k_buy'])\n",
    "# best_k_sell = float(best_row['k_sell'])\n",
    "# best_entry_delay = int(best_row['entry_delay'])\n",
    "# best_mode = best_row['entry_mode']\n",
    "# best_exit = best_row['exit_strategy']\n",
    "# best_max_units_cap = best_row['max_units_cap']\n",
    "# best_trade_dd_exit = best_row['trade_dd_exit']\n",
    "# best_portfolio_dd_cap = best_row['portfolio_dd_cap']\n",
    "\n",
    "# plot_dates = plot_df['date']\n",
    "# full_accum_series = full_df.set_index('date')['vw_accum']\n",
    "# full_valid_mask = ~full_accum_series.isna()\n",
    "\n",
    "# prior = full_accum_series.shift(1)\n",
    "# min_periods = best_window if ZSCORE_MIN_PERIODS is None else int(ZSCORE_MIN_PERIODS)\n",
    "# rolling_mean = prior.rolling(window=best_window, min_periods=min_periods).mean()\n",
    "# rolling_std = prior.rolling(window=best_window, min_periods=min_periods).std(ddof=0)\n",
    "# z_scores = (full_accum_series - rolling_mean) / rolling_std\n",
    "# ok_mask = full_valid_mask & rolling_mean.notna() & rolling_std.notna() & (rolling_std > 0)\n",
    "# pos_mask = ok_mask & (z_scores >= best_k_buy)\n",
    "# neg_mask = ok_mask & (z_scores <= -best_k_sell)\n",
    "# pos_dates = full_accum_series[pos_mask].index\n",
    "# neg_dates = full_accum_series[neg_mask].index\n",
    "\n",
    "# buy_dates = plot_dates[plot_dates.isin(pos_dates)]\n",
    "# sell_dates = plot_dates[plot_dates.isin(neg_dates)]\n",
    "\n",
    "# base_signal = pd.Series(0, index=plot_dates)\n",
    "# base_signal.loc[buy_dates] = 1\n",
    "# base_signal.loc[sell_dates] = -1\n",
    "# base_signal = base_signal.sort_index()\n",
    "# signal_trade = base_signal.shift(best_entry_delay).fillna(0)\n",
    "\n",
    "# def _build_position_buy_every(signal, prices=None, max_dd_exit=None):\n",
    "#     pos = []\n",
    "#     units = 0\n",
    "#     peak_value = 0.0\n",
    "#     entry_prices = []\n",
    "\n",
    "#     for i, sig in enumerate(signal):\n",
    "#         price = prices.iloc[i] if prices is not None else None\n",
    "#         if sig == 1:\n",
    "#             units += 1\n",
    "#             if price is not None:\n",
    "#                 entry_prices.append(price)\n",
    "#                 peak_value = sum(price for _ in entry_prices)\n",
    "#         elif sig == -1:\n",
    "#             units = 0\n",
    "#             peak_value = 0.0\n",
    "#             entry_prices = []\n",
    "#         if units > 0 and max_dd_exit is not None and price is not None and len(entry_prices) > 0:\n",
    "#             current_value = units * price\n",
    "#             peak_value = max(peak_value, current_value)\n",
    "#             if peak_value > 0:\n",
    "#                 dd_from_peak = (current_value - peak_value) / peak_value\n",
    "#                 if dd_from_peak <= -max_dd_exit:\n",
    "#                     units = 0\n",
    "#                     peak_value = 0.0\n",
    "#                     entry_prices = []\n",
    "#         pos.append(units)\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _build_position_ignore_long(signal, prices=None, max_dd_exit=None):\n",
    "#     pos = []\n",
    "#     current = 0\n",
    "#     entry_price = None\n",
    "#     peak_value = 0.0\n",
    "\n",
    "#     for i, sig in enumerate(signal):\n",
    "#         price = prices.iloc[i] if prices is not None else None\n",
    "#         if sig == 1:\n",
    "#             if current == 0:\n",
    "#                 current = 1\n",
    "#                 entry_price = price\n",
    "#                 peak_value = price if price else 0.0\n",
    "#         elif sig == -1:\n",
    "#             current = 0\n",
    "#             entry_price = None\n",
    "#             peak_value = 0.0\n",
    "#         if current > 0 and max_dd_exit is not None and price is not None and peak_value > 0:\n",
    "#             peak_value = max(peak_value, price)\n",
    "#             dd_from_peak = (price - peak_value) / peak_value\n",
    "#             if dd_from_peak <= -max_dd_exit:\n",
    "#                 current = 0\n",
    "#                 entry_price = None\n",
    "#                 peak_value = 0.0\n",
    "#         pos.append(current)\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _build_position_average_down_only(signal, prices, max_units=None, max_dd_exit=None):\n",
    "#     pos = []\n",
    "#     units = 0\n",
    "#     total_cost = 0.0\n",
    "#     peak_value = 0.0\n",
    "\n",
    "#     for i, (sig, price) in enumerate(zip(signal, prices)):\n",
    "#         if sig == 1:\n",
    "#             if units == 0:\n",
    "#                 units = 1\n",
    "#                 total_cost = price\n",
    "#                 peak_value = price\n",
    "#             else:\n",
    "#                 avg_entry_price = total_cost / units\n",
    "#                 can_add = (max_units is None) or (units < max_units)\n",
    "#                 if price < avg_entry_price and can_add:\n",
    "#                     units += 1\n",
    "#                     total_cost += price\n",
    "#         elif sig == -1:\n",
    "#             units = 0\n",
    "#             total_cost = 0.0\n",
    "#             peak_value = 0.0\n",
    "#         if units > 0 and max_dd_exit is not None and peak_value > 0:\n",
    "#             current_value = units * price\n",
    "#             peak_value = max(peak_value, current_value)\n",
    "#             dd_from_peak = (current_value - peak_value) / peak_value\n",
    "#             if dd_from_peak <= -max_dd_exit:\n",
    "#                 units = 0\n",
    "#                 total_cost = 0.0\n",
    "#                 peak_value = 0.0\n",
    "#         pos.append(units)\n",
    "#     return pd.Series(pos, index=signal.index)\n",
    "\n",
    "# def _apply_portfolio_dd_cap(position, returns, portfolio_max_dd):\n",
    "#     \"\"\"Apply portfolio-level drawdown cap. Once hit, go flat and stay flat.\"\"\"\n",
    "#     if portfolio_max_dd is None:\n",
    "#         return position\n",
    "#     capped_pos = position.copy()\n",
    "#     equity = 1.0\n",
    "#     peak_equity = 1.0\n",
    "#     stopped_out = False\n",
    "#     for i, (pos, ret) in enumerate(zip(position, returns)):\n",
    "#         if stopped_out:\n",
    "#             capped_pos.iloc[i] = 0\n",
    "#             continue\n",
    "#         equity = equity * (1.0 + ret * pos)\n",
    "#         peak_equity = max(peak_equity, equity)\n",
    "#         if peak_equity > 0:\n",
    "#             portfolio_dd = (equity - peak_equity) / peak_equity\n",
    "#             if portfolio_dd <= -portfolio_max_dd:\n",
    "#                 stopped_out = True\n",
    "#                 capped_pos.iloc[i] = 0\n",
    "#     return capped_pos\n",
    "\n",
    "# def _load_price_series(symbol):\n",
    "#     query = '''\n",
    "#         SELECT trade_date AS date, close\n",
    "#         FROM polygon_daily_agg_raw\n",
    "#         WHERE symbol = ? AND trade_date BETWEEN ? AND ?\n",
    "#         ORDER BY trade_date\n",
    "#     '''\n",
    "#     with duckdb.connect(str(DB_PATH), read_only=True) as conn:\n",
    "#         price_df = conn.execute(query, [symbol, START_DATE, END_DATE]).df()\n",
    "#     if price_df.empty:\n",
    "#         raise ValueError(f'No price data found for {symbol}.')\n",
    "#     price_df['date'] = pd.to_datetime(price_df['date'])\n",
    "#     price_df['close'] = pd.to_numeric(price_df['close'], errors='coerce')\n",
    "#     price_df = price_df.dropna(subset=['close']).set_index('date')\n",
    "#     price_df = price_df.reindex(plot_dates).dropna()\n",
    "#     return price_df['close']\n",
    "\n",
    "# def _calc_drawdown(equity_curve):\n",
    "#     running_max = equity_curve.cummax()\n",
    "#     return (equity_curve / running_max - 1.0) * 100.0\n",
    "\n",
    "# def _max_drawdown(equity_curve):\n",
    "#     running_max = equity_curve.cummax()\n",
    "#     return (equity_curve / running_max - 1.0).min()\n",
    "\n",
    "# # Parse parameters from best row\n",
    "# def _parse_pct(val):\n",
    "#     if val == 'None' or val is None:\n",
    "#         return None\n",
    "#     if isinstance(val, str) and '%' in val:\n",
    "#         return float(val.replace('%', '')) / 100.0\n",
    "#     if isinstance(val, (int, float)):\n",
    "#         return float(val)\n",
    "#     return None\n",
    "\n",
    "# trade_dd_val = _parse_pct(best_trade_dd_exit)\n",
    "# portfolio_dd_val = _parse_pct(best_portfolio_dd_cap)\n",
    "\n",
    "# if best_max_units_cap == 'N/A' or best_max_units_cap == 'unlimited':\n",
    "#     max_cap = None\n",
    "# elif isinstance(best_max_units_cap, (int, float)):\n",
    "#     max_cap = int(best_max_units_cap)\n",
    "# else:\n",
    "#     max_cap = None\n",
    "\n",
    "# strategy_symbol = TICKER\n",
    "# benchmark_symbols = ['SPY', 'QQQ']\n",
    "\n",
    "# # Load prices and build position\n",
    "# prices_for_pos = _load_price_series(strategy_symbol)\n",
    "# prices_aligned = prices_for_pos.reindex(signal_trade.index).ffill()\n",
    "\n",
    "# if best_mode == 'buy_every_signal':\n",
    "#     position = _build_position_buy_every(signal_trade, prices_aligned, max_dd_exit=trade_dd_val)\n",
    "# elif best_mode == 'ignore_while_long':\n",
    "#     position = _build_position_ignore_long(signal_trade, prices_aligned, max_dd_exit=trade_dd_val)\n",
    "# elif best_mode == 'average_down_only':\n",
    "#     position = _build_position_average_down_only(\n",
    "#         signal_trade, prices_aligned, max_units=max_cap, max_dd_exit=trade_dd_val\n",
    "#     )\n",
    "# else:\n",
    "#     raise ValueError(f'Unknown position mode: {best_mode}')\n",
    "\n",
    "# # Apply portfolio-level drawdown cap\n",
    "# prices = _load_price_series(strategy_symbol)\n",
    "# returns = prices.pct_change().fillna(0)\n",
    "# position = _apply_portfolio_dd_cap(position.reindex(returns.index).fillna(0), returns, portfolio_dd_val)\n",
    "\n",
    "# equity = {}\n",
    "# drawdowns = {}\n",
    "\n",
    "# # Strategy equity\n",
    "# aligned_pos = position.reindex(returns.index).fillna(0)\n",
    "# strat_eq = (1.0 + returns * aligned_pos).cumprod()\n",
    "# equity[f'{strategy_symbol} Strategy'] = strat_eq\n",
    "# drawdowns[f'{strategy_symbol} Strategy'] = _calc_drawdown(strat_eq)\n",
    "\n",
    "# # Benchmark equities\n",
    "# for symbol in benchmark_symbols:\n",
    "#     prices = _load_price_series(symbol)\n",
    "#     returns = prices.pct_change().fillna(0)\n",
    "#     bh_eq = (1.0 + returns).cumprod()\n",
    "#     equity[f'{symbol} B&H'] = bh_eq\n",
    "#     drawdowns[f'{symbol} B&H'] = _calc_drawdown(bh_eq)\n",
    "\n",
    "# colors = {\n",
    "#     f'{strategy_symbol} Strategy': '#00d4ff',\n",
    "#     'SPY B&H': '#ffffff',\n",
    "#     'QQQ B&H': '#ffd700',\n",
    "# }\n",
    "\n",
    "# fig, (ax_return, ax_dd) = plt.subplots(2, 1, figsize=(12, 7), sharex=True, \n",
    "#                                         gridspec_kw={'height_ratios': [1.2, 1], 'hspace': 0.08})\n",
    "# fig.patch.set_facecolor('#0f0f10')\n",
    "\n",
    "# # Panel 1: % Return\n",
    "# ax_return.set_facecolor('#141416')\n",
    "# for label, eq in equity.items():\n",
    "#     eq_pct = (eq - 1.0) * 100.0\n",
    "#     lw = 2.0 if 'Strategy' in label else 1.4\n",
    "#     alpha = 1.0 if 'Strategy' in label else 0.8\n",
    "#     ax_return.plot(eq_pct.index, eq_pct.values, label=label, color=colors[label], linewidth=lw, alpha=alpha)\n",
    "\n",
    "# ax_return.axhline(0, color='#6b6b6b', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "# ax_return.set_ylabel('Return (%)', color='#e6e6e6', fontsize=11)\n",
    "# ax_return.set_title('Best Settings: Strategy vs Buy-and-Hold', color='#e6e6e6', fontsize=13, fontweight='bold', loc='left')\n",
    "# ax_return.tick_params(colors='#e6e6e6')\n",
    "# ax_return.grid(True, linestyle='--', alpha=0.2, color='#2a2a2d')\n",
    "# ax_return.legend(loc='upper left', fontsize=9, framealpha=0.7)\n",
    "# ax_return.spines['top'].set_visible(False)\n",
    "# ax_return.spines['right'].set_visible(False)\n",
    "# ax_return.spines['left'].set_color('#2a2a2d')\n",
    "# ax_return.spines['bottom'].set_color('#2a2a2d')\n",
    "\n",
    "# for label, eq in equity.items():\n",
    "#     final_ret = (eq.iloc[-1] - 1.0) * 100.0\n",
    "#     ax_return.annotate(f'{final_ret:+.1f}%', xy=(eq.index[-1], final_ret), \n",
    "#                        xytext=(5, 0), textcoords='offset points',\n",
    "#                        color=colors[label], fontsize=9, fontweight='bold', va='center')\n",
    "\n",
    "# # Panel 2: % Drawdown\n",
    "# ax_dd.set_facecolor('#141416')\n",
    "# for label, dd in drawdowns.items():\n",
    "#     lw = 2.0 if 'Strategy' in label else 1.4\n",
    "#     alpha = 1.0 if 'Strategy' in label else 0.8\n",
    "#     ax_dd.fill_between(dd.index, dd.values, 0, alpha=0.15, color=colors[label])\n",
    "#     ax_dd.plot(dd.index, dd.values, label=label, color=colors[label], linewidth=lw, alpha=alpha)\n",
    "\n",
    "# ax_dd.axhline(0, color='#6b6b6b', linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "# ax_dd.set_ylabel('Drawdown (%)', color='#e6e6e6', fontsize=11)\n",
    "# ax_dd.set_xlabel('Date', color='#e6e6e6', fontsize=11)\n",
    "# ax_dd.tick_params(colors='#e6e6e6')\n",
    "# ax_dd.grid(True, linestyle='--', alpha=0.2, color='#2a2a2d')\n",
    "# ax_dd.legend(loc='lower left', fontsize=9, framealpha=0.7)\n",
    "# ax_dd.spines['top'].set_visible(False)\n",
    "# ax_dd.spines['right'].set_visible(False)\n",
    "# ax_dd.spines['left'].set_color('#2a2a2d')\n",
    "# ax_dd.spines['bottom'].set_color('#2a2a2d')\n",
    "\n",
    "# for label, dd in drawdowns.items():\n",
    "#     max_dd = dd.min()\n",
    "#     max_dd_date = dd.idxmin()\n",
    "#     ax_dd.annotate(f'{max_dd:.1f}%', xy=(max_dd_date, max_dd), \n",
    "#                    xytext=(0, -12), textcoords='offset points',\n",
    "#                    color=colors[label], fontsize=8, fontweight='bold', ha='center')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # Summary\n",
    "# print()\n",
    "# print('=' * 70)\n",
    "# print('STRATEGY SETTINGS:')\n",
    "# print('-' * 70)\n",
    "# print(f\"  Entry Mode:       {best_mode}\")\n",
    "# print(f\"  Max Units Cap:    {best_max_units_cap}\")\n",
    "# print(f\"  Exit Strategy:    {best_exit}\")\n",
    "# print(f\"  Trade DD Exit:    {best_trade_dd_exit} (per-trade stop-loss)\")\n",
    "# print(f\"  Portfolio DD Cap: {best_portfolio_dd_cap} (overall cap - stops all trading)\")\n",
    "# print(f\"  Max Units Cap:    {best_max_units_cap}\")\n",
    "# print(f\"  Rolling Window:   {best_window} days | K Buy: +{best_k_buy:.1f} | K Sell: -{best_k_sell:.1f}\")\n",
    "# print(f\"  Entry Delay:      {best_entry_delay} days\")\n",
    "# print('=' * 70)\n",
    "# print()\n",
    "# print('PERFORMANCE SUMMARY:')\n",
    "# print('-' * 70)\n",
    "# print(f'{\"Series\":<20} {\"Total Return\":>15} {\"Max Drawdown\":>15}')\n",
    "# print('-' * 70)\n",
    "# for label, eq in equity.items():\n",
    "#     total_ret = (eq.iloc[-1] - 1.0) * 100.0\n",
    "#     max_dd = _max_drawdown(eq) * 100.0\n",
    "#     print(f'{label:<20} {total_ret:>+14.2f}% {max_dd:>14.2f}%')\n",
    "# print('=' * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}